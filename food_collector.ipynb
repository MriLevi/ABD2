{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ABD2\n",
    "\n",
    "Wij gaan tijdens deze opdracht een food-collector simulatie bouwen.\n",
    "In deze simulatie is het doel van de agents om zo veel mogelijk groen eten op te eten, terwijl ze rood eten vermijden.\n",
    "We gaan deze simulatie grid-based maken. \n",
    "\n",
    "We maken gebruik van de gymnasium API: https://gymnasium.farama.org/\n",
    "\n",
    "Ter visualisatie gebruiken we pygame.\n",
    "\n",
    "\n",
    "\n",
    "### Simulation properties:\n",
    "We beginnen in principe met een grid van 128x128, maar dit kan uitgebreid worden. \n",
    "We zullen de implementatie zoveel mogelijk scalable en aanpasbaar implementeren, door hyperparameters aan te maken voor alle belangrijke properties.\n",
    "\n",
    "- Number of agents\n",
    "- Grid size (default 128x128)\n",
    "- Good food to total square ratio\n",
    "- Good food spawning pattern (maybe)\n",
    "- Bad food to total square ratio\n",
    "- Bad food spawning pattern (maybe)\n",
    "- Episode duration\n",
    "\n",
    "### Agent properties:\n",
    "Actions: up, down, left, right, wait\n",
    "\n",
    "Perception: full information (knows coordinates of other agents, good food, and bad food)\n",
    "\n",
    "Agent rules: not yet specified\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pygame\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
    "observation, info = env.reset()\n",
    "\n",
    "for _ in range(100):\n",
    "    action = env.action_space.sample()  # agent policy that uses the observation and info\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class agent():\n",
    "    def __init__(self):\n",
    "        self.location = [None,None]\n",
    "        self.points = 0\n",
    "        \n",
    "    def move(self, direction, grid_size):\n",
    "        \n",
    "        new_location = np.clip(self.location + direction, 0, grid_size -1)\n",
    "        self.location = new_location\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class foodCollectorEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", None], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self, render_mode=None, grid_size=128, game_duration = 200, agents = [agent() for _ in range(1)]):\n",
    "        self.grid_size = grid_size  # The size of the square grid\n",
    "        self.window_size = 512  # The size of the PyGame window\n",
    "        self.game_duration = game_duration\n",
    "        self.current_step = 0\n",
    "        self.agents = agents\n",
    "        \n",
    "        self.observation_space = spaces.Dict({\n",
    "            'agent_locs': spaces.Sequence(spaces.MultiDiscrete([self.grid_size-1,self.grid_size-1])),\n",
    "            'good_food_locs':spaces.Sequence(spaces.MultiDiscrete([self.grid_size-1,self.grid_size-1])),\n",
    "            'bad_food_locs':spaces.Sequence(spaces.MultiDiscrete([self.grid_size-1,self.grid_size-1])),\n",
    "        })\n",
    "\n",
    "\n",
    "        self.action_space = spaces.Discrete(5)\n",
    "\n",
    "\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([0, 0]),\n",
    "            1: np.array([1, 0]),\n",
    "            2: np.array([0, 1]),\n",
    "            3: np.array([-1, 0]),\n",
    "            4:np.array([0, -1])\n",
    "        }\n",
    "\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "        \n",
    "    def _get_obs(self):\n",
    "        return {\n",
    "            \"agent_locs\": [agent.location for agent in self.agents],\n",
    "            \"good_food_locs\": self.good_food_locs,\n",
    "            \"bad_food_locs\": self.bad_food_locs\n",
    "        }\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        self.agent_locs = []\n",
    "        self.good_food_locs = []\n",
    "        self.bad_food_locs = []\n",
    "        \n",
    "        print([len(self.agent_locs), len(self.agents)])\n",
    "        \n",
    "            \n",
    "        while True:\n",
    "            if len(self.agent_locs) >= len(self.agents):\n",
    "                break\n",
    "            loc = [random.randint(0,self.grid_size),random.randint(0,self.grid_size)]\n",
    "            if loc not in self.agent_locs:\n",
    "                self.agent_locs.append(loc)\n",
    "                \n",
    "        for i, agent in enumerate(self.agents):\n",
    "            agent.location = self.agent_locs[i]\n",
    "                \n",
    "        \n",
    "        observation = self._get_obs()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        return observation, info\n",
    "    \n",
    "    def step(self, action):\n",
    "        for agent in self.agents:\n",
    "            \n",
    "        \n",
    "            direction = self._action_to_direction[action[0]]\n",
    "            \n",
    "            if self._is_empty(np.clip(agent.location + direction, 0, self.grid_size -1)):\n",
    "                \n",
    "                agent.move(direction, self.grid_size)\n",
    "            else:\n",
    "                agent.move(self._action_to_direction[0], self.grid_size)\n",
    "                \n",
    "            \n",
    "        terminated = self.current_step >= self.game_duration\n",
    "        reward = 1 if terminated else 0  # \n",
    "        observation = self._get_obs()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "        info = {}\n",
    "        \n",
    "        self.current_step += 1\n",
    "        \n",
    "        return observation, reward, terminated, info\n",
    "    \n",
    "    def _is_empty(self,loc):\n",
    "        \n",
    "        for agent in self.agents:\n",
    "            if sorted(agent.location) == sorted(loc):\n",
    "                return False\n",
    "            \n",
    "        return True\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = foodCollectorEnv(render_mode=None, grid_size=128, game_duration = 200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env.observation_space.sample()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env.step([1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class foodCollectorEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", None], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self, render_mode=None, grid_size=128, game_duration = 200, agents = [agent() for _ in range(1)]):\n",
    "        self.grid_size = grid_size  # The size of the square grid\n",
    "        self.window_size = 512  # The size of the PyGame window\n",
    "        self.game_duration = game_duration\n",
    "        self.current_step = 0\n",
    "        self.agents = agents\n",
    "        \n",
    "        self.observation_space = spaces.Dict({\n",
    "            'agent_locs': spaces.Sequence(spaces.MultiDiscrete([self.grid_size-1,self.grid_size-1])),\n",
    "            'good_food_locs':spaces.Sequence(spaces.MultiDiscrete([self.grid_size-1,self.grid_size-1])),\n",
    "            'bad_food_locs':spaces.Sequence(spaces.MultiDiscrete([self.grid_size-1,self.grid_size-1])),\n",
    "        })\n",
    "\n",
    "\n",
    "        self.action_space = spaces.Discrete(5)\n",
    "\n",
    "\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([0, 0]),\n",
    "            1: np.array([1, 0]),\n",
    "            2: np.array([0, 1]),\n",
    "            3: np.array([-1, 0]),\n",
    "            4:np.array([0, -1])\n",
    "        }\n",
    "\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        self.window = None\n",
    "        self.clock = None\n",
    "        \n",
    "    def _get_obs(self):\n",
    "        return {\n",
    "            \"agent_locs\": [agent.location for agent in self.agents],\n",
    "            \"good_food_locs\": self.good_food_locs,\n",
    "            \"bad_food_locs\": self.bad_food_locs\n",
    "        }\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        self.agent_locs = []\n",
    "        self.good_food_locs = []\n",
    "        self.bad_food_locs = []\n",
    "        \n",
    "        print([len(self.agent_locs), len(self.agents)])\n",
    "        \n",
    "            \n",
    "        while True:\n",
    "            if len(self.agent_locs) >= len(self.agents):\n",
    "                break\n",
    "            loc = [random.randint(0,self.grid_size),random.randint(0,self.grid_size)]\n",
    "            if loc not in self.agent_locs:\n",
    "                self.agent_locs.append(loc)\n",
    "                \n",
    "        for i, agent in enumerate(self.agents):\n",
    "            agent.location = self.agent_locs[i]\n",
    "                \n",
    "        \n",
    "        observation = self._get_obs()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        return observation, info\n",
    "    \n",
    "    def step(self, action):\n",
    "        for agent in self.agents:\n",
    "            \n",
    "        \n",
    "            direction = self._action_to_direction[action[0]]\n",
    "            \n",
    "            if self._is_empty(np.clip(agent.location + direction, 0, self.grid_size -1)):\n",
    "                \n",
    "                agent.move(direction, self.grid_size)\n",
    "            else:\n",
    "                agent.move(self._action_to_direction[0], self.grid_size)\n",
    "                \n",
    "            \n",
    "        terminated = self.current_step >= self.game_duration\n",
    "        reward = 1 if terminated else 0  # \n",
    "        observation = self._get_obs()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "        info = {}\n",
    "        \n",
    "        self.current_step += 1\n",
    "        \n",
    "        return observation, reward, terminated, info\n",
    "    \n",
    "    def _is_empty(self,loc):\n",
    "        \n",
    "        for agent in self.agents:\n",
    "            if sorted(agent.location) == sorted(loc):\n",
    "                return False\n",
    "            \n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = foodCollectorEnv(render_mode=None, grid_size=128, game_duration = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('agent_locs',\n",
       "              (array([19, 70], dtype=int64), array([98, 62], dtype=int64))),\n",
       "             ('bad_food_locs', (array([24, 70], dtype=int64),)),\n",
       "             ('good_food_locs',\n",
       "              (array([37, 64], dtype=int64),\n",
       "               array([ 77, 125], dtype=int64),\n",
       "               array([54, 30], dtype=int64),\n",
       "               array([72, 69], dtype=int64),\n",
       "               array([76, 99], dtype=int64),\n",
       "               array([ 4, 12], dtype=int64),\n",
       "               array([24, 72], dtype=int64),\n",
       "               array([90, 64], dtype=int64),\n",
       "               array([ 64, 117], dtype=int64)))])"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'agent_locs': [[28, 36]], 'good_food_locs': [], 'bad_food_locs': []}, {})"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'agent_locs': [array([127,  36])],\n",
       "  'good_food_locs': [],\n",
       "  'bad_food_locs': []},\n",
       " 1,\n",
       " True,\n",
       " {})"
      ]
     },
     "execution_count": 1055,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}