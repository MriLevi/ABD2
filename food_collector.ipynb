{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABD2\n",
    "\n",
    "Wij gaan tijdens deze opdracht een food-collector simulatie bouwen.\n",
    "In deze simulatie is het doel van de agents om zo veel mogelijk groen eten op te eten, terwijl ze rood eten vermijden.\n",
    "We gaan deze simulatie grid-based maken. \n",
    "\n",
    "We maken gebruik van de gymnasium API: https://gymnasium.farama.org/\n",
    "\n",
    "Ter visualisatie gebruiken we pygame.\n",
    "\n",
    "\n",
    "\n",
    "### Simulation properties:\n",
    "We beginnen in principe met een grid van 128x128, maar dit kan uitgebreid worden. \n",
    "We zullen de implementatie zoveel mogelijk scalable en aanpasbaar implementeren, door hyperparameters aan te maken voor alle belangrijke properties.\n",
    "\n",
    "- Number of agents\n",
    "- Grid size (default 128x128)\n",
    "- Good food to total square ratio\n",
    "- Good food spawning pattern (maybe)\n",
    "- Bad food to total square ratio\n",
    "- Bad food spawning pattern (maybe)\n",
    "- Episode duration\n",
    "\n",
    "### Agent properties:\n",
    "Actions: up, down, left, right, wait\n",
    "\n",
    "Perception: full information (knows coordinates of other agents, good food, and bad food)\n",
    "\n",
    "Agent rules: not yet specified\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.3 (SDL 2.0.22, Python 3.9.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pygame\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class agent():\n",
    "    def __init__(self):\n",
    "        self.location = [None, None]\n",
    "        self.points = 0\n",
    "        self.vision_range = 3\n",
    "        self.memory = []\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([0, 0]),\n",
    "            1: np.array([1, 0]),\n",
    "            2: np.array([0, 1]),\n",
    "            3: np.array([-1, 0]),\n",
    "            4: np.array([0, -1])\n",
    "        }\n",
    "\n",
    "    def move(self, direction, grid_size):\n",
    "        new_location = self.location + direction\n",
    "        self.location = list(new_location)\n",
    "\n",
    "    def clip_vision(self, obs):\n",
    "\n",
    "        clipped_obs = {}\n",
    "\n",
    "        for k in obs.keys():\n",
    "\n",
    "            clipped_obs[k] = [x for x in obs[k]\n",
    "                      if abs(self.location[0] - x[0]) <= self.vision_range\n",
    "                      and abs(self.location[1] - x[1]) <= self.vision_range\n",
    "                     ]\n",
    "\n",
    "        return clipped_obs\n",
    "\n",
    "    def pick_action(self,obs, grid_size):\n",
    "\n",
    "        print(f\"OG obs: {obs['good_food_locs']}\")\n",
    "        # clip the observation to the agents vision\n",
    "        obs = self.clip_vision(obs)\n",
    "        \n",
    "        print(f\"clipped obs {obs['good_food_locs']}\")\n",
    "        print(f\"location {self.location}\")\n",
    "        print()\n",
    "\n",
    "        viable_actions = list(self._action_to_direction.keys())\n",
    "\n",
    "        other_agent_locations = [x for x in obs['agent_locs'] if x != self.location]\n",
    "\n",
    "        # Rule 1: agents can't move to a space occupied by another agent\n",
    "        viable_actions = [v for v in viable_actions if list(self.location +  self._action_to_direction[v]) not in other_agent_locations]\n",
    "        # Rule 2: agents can't move out of bounds\n",
    "        viable_actions = [v for v in viable_actions\n",
    "                          if list(self.location +  self._action_to_direction[v])[0] >= 0\n",
    "                          and list(self.location +  self._action_to_direction[v])[1] >= 0\n",
    "                          and list(self.location +  self._action_to_direction[v])[0] < grid_size\n",
    "                          and list(self.location +  self._action_to_direction[v])[1] < grid_size]\n",
    "\n",
    "        action = random.choice(viable_actions)\n",
    "        self.memory.append({'agent_action':action, \"agent_obs\":obs, \"agent_location\":self.location})\n",
    "        return action\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class foodCollectorEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", None], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self, render_mode=None, grid_size=128, game_duration=200, agents=1, good_food_ratio=0.1,\n",
    "                 bad_food_ratio=0.1):\n",
    "        self.grid_size = grid_size\n",
    "        self.window_size = 720\n",
    "        self.game_duration = game_duration * agents\n",
    "        self.current_step = 0\n",
    "        self.agents = [agent() for _ in range(agents)]\n",
    "        self.good_food_ratio = good_food_ratio\n",
    "        self.bad_food_ratio = bad_food_ratio\n",
    "        self.good_food_points = 5\n",
    "        self.bad_food_points = -1\n",
    "        self.render_mode = render_mode\n",
    "        self.window = None\n",
    "\n",
    "\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'agent_locs': spaces.Sequence(spaces.MultiDiscrete([self.grid_size - 1, self.grid_size - 1])),\n",
    "            'good_food_locs': spaces.Sequence(spaces.MultiDiscrete([self.grid_size - 1, self.grid_size - 1])),\n",
    "            'bad_food_locs': spaces.Sequence(spaces.MultiDiscrete([self.grid_size - 1, self.grid_size - 1])),\n",
    "        })\n",
    "\n",
    "        self.action_space = spaces.Sequence(spaces.Tuple((spaces.MultiDiscrete(len(self.agents)) ,spaces.MultiDiscrete(5) )))\n",
    "\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([0, 0]),\n",
    "            1: np.array([1, 0]),\n",
    "            2: np.array([0, 1]),\n",
    "            3: np.array([-1, 0]),\n",
    "            4: np.array([0, -1])\n",
    "        }\n",
    "\n",
    "        self.good_food_locations = []\n",
    "        self.bad_food_locations = []\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return {\n",
    "            \"agent_locs\": [agent.location for agent in self.agents],\n",
    "            \"good_food_locs\": self.good_food_locs,\n",
    "            \"bad_food_locs\": self.bad_food_locs\n",
    "        }\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        self.agent_locs = []\n",
    "        self.good_food_locs = []\n",
    "        self.bad_food_locs = []\n",
    "\n",
    "\n",
    "        # place agents\n",
    "        while True:\n",
    "            if len(self.agent_locs) >= len(self.agents):\n",
    "                break\n",
    "            loc = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]\n",
    "            if loc not in self.agent_locs:\n",
    "                self.agent_locs.append(loc)\n",
    "\n",
    "\n",
    "        # place good food\n",
    "        while True:\n",
    "            if len(self.good_food_locs) >= round(self.good_food_ratio * self.grid_size * self.grid_size):\n",
    "                break\n",
    "            loc = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]\n",
    "            if loc not in self.agent_locs and loc not in self.good_food_locs and loc not in self.bad_food_locs:\n",
    "                self.good_food_locs.append(loc)\n",
    "\n",
    "        #place bad food\n",
    "        while True:\n",
    "            if len(self.bad_food_locs) >= round(self.bad_food_ratio * self.grid_size * self.grid_size):\n",
    "                break\n",
    "            loc = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]\n",
    "            if loc not in self.agent_locs and loc not in self.good_food_locs and loc not in self.bad_food_locs:\n",
    "                self.bad_food_locs.append(loc)\n",
    "\n",
    "        for i, agent in enumerate(self.agents):\n",
    "            agent.location = self.agent_locs[i]\n",
    "\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        info = {\"agent_points\": [agent.points for agent in self.agents]}\n",
    "\n",
    "        return observation, info\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        direction = self._action_to_direction[action[1]]\n",
    "\n",
    "        self.agents[action[0]].move(direction, self.grid_size)\n",
    "\n",
    "        if self.agents[action[0]].location in self.good_food_locs:\n",
    "            self.good_food_locs.remove(self.agents[action[0]].location)\n",
    "            self.agents[action[0]].points += self.good_food_points\n",
    "\n",
    "        if self.agents[action[0]].location in self.bad_food_locs:\n",
    "            self.bad_food_locs.remove(self.agents[action[0]].location)\n",
    "            self.agents[action[0]].points += self.bad_food_points\n",
    "\n",
    "        terminated = self.current_step >= self.game_duration or (len(self._get_obs()['good_food_locs']) == 0 and self.current_step > 0)\n",
    "        reward = 0 # niet relevant voor nu\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "        info = {\"agent_points\": [agent.points for agent in self.agents]}\n",
    "\n",
    "        self.current_step += 1\n",
    "        time.sleep(0)\n",
    "\n",
    "        return observation, reward, terminated, info\n",
    "\n",
    "    def _is_empty(self, loc):\n",
    "\n",
    "        for agent in self.agents:\n",
    "            if sorted(agent.location) == sorted(loc):\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == \"rgb_array\":\n",
    "            return self._render_frame()\n",
    "\n",
    "    def _render_frame(self):\n",
    "        pygame.font.init()\n",
    "        font = pygame.font.Font(None, 24)\n",
    "        scoreboard_width = 0.2\n",
    "\n",
    "        if self.window is None and self.render_mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.window = pygame.display.set_mode(\n",
    "                (self.window_size + self.window_size * scoreboard_width, self.window_size)\n",
    "            )\n",
    "\n",
    "        canvas = pygame.Surface((self.window_size + self.window_size * scoreboard_width, self.window_size))\n",
    "        canvas.fill((204, 255, 229))\n",
    "        pix_square_size = (\n",
    "                self.window_size / self.grid_size\n",
    "        )\n",
    "\n",
    "\n",
    "        for i, agent in enumerate(self.agents):\n",
    "            deer_image = pygame.image.load(\"deer.png\").convert_alpha()\n",
    "            deer_image = pygame.transform.scale(deer_image, (pix_square_size, pix_square_size))\n",
    "            canvas.blit(deer_image, (agent.location[0] * pix_square_size, (self.grid_size - 1 - agent.location[1]) * pix_square_size))\n",
    "\n",
    "            #try to draw vision_range, a bit awkward imo\n",
    "            fov = pygame.Surface((pix_square_size * (agent.vision_range*2+1), pix_square_size * (agent.vision_range*2+1)))\n",
    "            fov.set_alpha(128)\n",
    "            fov.fill((137,137,137))\n",
    "            canvas.blit(fov, ((agent.location[0] * pix_square_size)-pix_square_size*agent.vision_range, ((self.grid_size - 1 - agent.location[1]) * pix_square_size) - pix_square_size * agent.vision_range))\n",
    "\n",
    "            scoreboard_bg = pygame.Surface((self.window_size*scoreboard_width,self.window_size+self.window_size*scoreboard_width))\n",
    "            scoreboard_bg.fill((255, 255, 255))\n",
    "            scoreboard_bg.set_alpha(255)\n",
    "\n",
    "            canvas.blit(scoreboard_bg, (self.window_size, 0))\n",
    "            score_text = font.render(f\"{i}\", True, \"white\")\n",
    "            canvas.blit(score_text, (agent.location[0] * pix_square_size, (self.grid_size - 1 - agent.location[1]) * pix_square_size))\n",
    "\n",
    "\n",
    "\n",
    "        for gfl in self.good_food_locs:\n",
    "            good_food_image = pygame.image.load(\"plant.png\").convert_alpha()\n",
    "            good_food_image = pygame.transform.scale(good_food_image, (pix_square_size, pix_square_size))\n",
    "            canvas.blit(good_food_image, (gfl[0] * pix_square_size, (self.grid_size - 1 - gfl[1]) * pix_square_size))\n",
    "\n",
    "        for bfl in self.bad_food_locs:\n",
    "            bad_food_image = pygame.image.load(\"evil_plant.png\").convert_alpha()\n",
    "            bad_food_image = pygame.transform.scale(bad_food_image, (pix_square_size, pix_square_size))\n",
    "            canvas.blit(bad_food_image, (bfl[0] * pix_square_size, (self.grid_size - 1 - bfl[1]) * pix_square_size))\n",
    "\n",
    "        for x in range(self.grid_size + 1):\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                color=0,\n",
    "                start_pos=(0, pix_square_size * x),\n",
    "                end_pos=(self.window_size, pix_square_size * x),\n",
    "                width=1,\n",
    "            )\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                color=0,\n",
    "                start_pos=(pix_square_size * x, 0),\n",
    "                end_pos=(pix_square_size * x, self.window_size),\n",
    "                width=1,\n",
    "            )\n",
    "\n",
    "        for i, agent in enumerate(self.agents):\n",
    "\n",
    "            score_text = font.render(f'Agent {i} | {agent.points}', True, \"black\")\n",
    "            canvas.blit(score_text, (self.window_size + 10 , 10 + (i*50)))\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "\n",
    "            self.window.blit(canvas, canvas.get_rect())\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "\n",
    "            #self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        else:\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
    "            )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = foodCollectorEnv(render_mode=\"human\", grid_size=16, game_duration=50, agents=10, good_food_ratio=0.01,\n",
    "                       bad_food_ratio=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "observation = env._get_obs()\n",
    "while True:\n",
    "    \n",
    "    for i in range(len(env.agents)):\n",
    "        \n",
    "        action = [i,env.agents[i].pick_action(observation, env.grid_size)]\n",
    "        observation, reward, terminated, info = env.step(action)\n",
    "\n",
    "    if terminated:\n",
    "        break\n",
    "pygame.quit()    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(info)\n",
    "np.argmax(info['agent_points'])\n",
    "print(f\"Agent {np.argmax(info['agent_points'])} wins the game with {max(info['agent_points'])} points\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env.agents[0].memory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'agent_action': 3,\n",
       "  'agent_obs': {'agent_locs': [[2, 4], [3, 7], [4, 6]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[2, 3],\n",
       "    [1, 6],\n",
       "    [2, 1],\n",
       "    [5, 7],\n",
       "    [0, 5],\n",
       "    [1, 1],\n",
       "    [5, 6],\n",
       "    [5, 2],\n",
       "    [4, 1]]},\n",
       "  'agent_location': [2, 4]},\n",
       " {'agent_action': 0,\n",
       "  'agent_obs': {'agent_locs': [[1, 4], [2, 7], [4, 6]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[2, 3], [1, 6], [2, 1], [0, 5], [1, 1], [4, 1]]},\n",
       "  'agent_location': [1, 4]},\n",
       " {'agent_action': 1,\n",
       "  'agent_obs': {'agent_locs': [[1, 4], [1, 7], [4, 7]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[2, 3], [1, 6], [2, 1], [0, 5], [1, 1], [4, 1]]},\n",
       "  'agent_location': [1, 4]},\n",
       " {'agent_action': 2,\n",
       "  'agent_obs': {'agent_locs': [[2, 4], [2, 7], [4, 7]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[2, 3],\n",
       "    [1, 6],\n",
       "    [2, 1],\n",
       "    [5, 7],\n",
       "    [0, 5],\n",
       "    [1, 1],\n",
       "    [5, 6],\n",
       "    [5, 2],\n",
       "    [4, 1]]},\n",
       "  'agent_location': [2, 4]},\n",
       " {'agent_action': 2,\n",
       "  'agent_obs': {'agent_locs': [[2, 5], [2, 8], [4, 7]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[2, 3], [1, 6], [5, 7], [0, 5], [5, 6], [5, 2]]},\n",
       "  'agent_location': [2, 5]},\n",
       " {'agent_action': 3,\n",
       "  'agent_obs': {'agent_locs': [[2, 6], [1, 8], [5, 7], [2, 9]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[2, 3], [1, 6], [0, 5], [5, 6]]},\n",
       "  'agent_location': [2, 6]},\n",
       " {'agent_action': 3,\n",
       "  'agent_obs': {'agent_locs': [[1, 6], [1, 9], [2, 9]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[2, 3], [0, 5]]},\n",
       "  'agent_location': [1, 6]},\n",
       " {'agent_action': 4,\n",
       "  'agent_obs': {'agent_locs': [[0, 6], [1, 8]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[2, 3], [0, 5]]},\n",
       "  'agent_location': [0, 6]},\n",
       " {'agent_action': 4,\n",
       "  'agent_obs': {'agent_locs': [[0, 5], [2, 8]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[2, 3]]},\n",
       "  'agent_location': [0, 5]},\n",
       " {'agent_action': 0,\n",
       "  'agent_obs': {'agent_locs': [[0, 4], [2, 7]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[2, 3], [2, 1], [1, 1]]},\n",
       "  'agent_location': [0, 4]},\n",
       " {'agent_action': 4,\n",
       "  'agent_obs': {'agent_locs': [[0, 4], [2, 7]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[2, 3], [2, 1], [1, 1]]},\n",
       "  'agent_location': [0, 4]},\n",
       " {'agent_action': 0,\n",
       "  'agent_obs': {'agent_locs': [[0, 3]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[2, 3], [2, 1], [1, 1]]},\n",
       "  'agent_location': [0, 3]},\n",
       " {'agent_action': 4,\n",
       "  'agent_obs': {'agent_locs': [[0, 3]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[2, 3], [2, 1], [1, 1]]},\n",
       "  'agent_location': [0, 3]},\n",
       " {'agent_action': 0,\n",
       "  'agent_obs': {'agent_locs': [[0, 2]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[2, 3], [2, 1], [1, 1]]},\n",
       "  'agent_location': [0, 2]},\n",
       " {'agent_action': 0,\n",
       "  'agent_obs': {'agent_locs': [[0, 2]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[2, 3], [2, 1], [1, 1]]},\n",
       "  'agent_location': [0, 2]},\n",
       " {'agent_action': 1,\n",
       "  'agent_obs': {'agent_locs': [[0, 2]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[2, 3], [2, 1], [1, 1]]},\n",
       "  'agent_location': [0, 2]},\n",
       " {'agent_action': 2,\n",
       "  'agent_obs': {'agent_locs': [[1, 2]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[4, 0], [2, 3], [2, 1], [1, 1], [4, 1]]},\n",
       "  'agent_location': [1, 2]},\n",
       " {'agent_action': 4,\n",
       "  'agent_obs': {'agent_locs': [[1, 3]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[4, 0], [2, 3], [2, 1], [1, 1], [4, 1]]},\n",
       "  'agent_location': [1, 3]},\n",
       " {'agent_action': 0,\n",
       "  'agent_obs': {'agent_locs': [[1, 2]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[4, 0], [2, 3], [2, 1], [1, 1], [4, 1]]},\n",
       "  'agent_location': [1, 2]},\n",
       " {'agent_action': 1,\n",
       "  'agent_obs': {'agent_locs': [[1, 2]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[4, 0], [2, 3], [2, 1], [1, 1], [4, 1]]},\n",
       "  'agent_location': [1, 2]},\n",
       " {'agent_action': 0,\n",
       "  'agent_obs': {'agent_locs': [[2, 2]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[4, 0], [2, 3], [2, 1], [1, 1], [5, 2], [4, 1]]},\n",
       "  'agent_location': [2, 2]},\n",
       " {'agent_action': 4,\n",
       "  'agent_obs': {'agent_locs': [[2, 2]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[4, 0], [2, 3], [2, 1], [1, 1], [5, 2], [4, 1]]},\n",
       "  'agent_location': [2, 2]},\n",
       " {'agent_action': 2,\n",
       "  'agent_obs': {'agent_locs': [[2, 1]],\n",
       "   'good_food_locs': [],\n",
       "   'bad_food_locs': [[4, 0], [2, 3], [1, 1], [5, 2], [4, 1]]},\n",
       "  'agent_location': [2, 1]},\n",
       " {'agent_action': 0,\n",
       "  'agent_obs': {'agent_locs': [[2, 2]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[4, 0], [2, 3], [1, 1], [5, 2], [4, 1]]},\n",
       "  'agent_location': [2, 2]},\n",
       " {'agent_action': 2,\n",
       "  'agent_obs': {'agent_locs': [[2, 2]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[4, 0], [2, 3], [1, 1], [5, 2], [4, 1]]},\n",
       "  'agent_location': [2, 2]},\n",
       " {'agent_action': 1,\n",
       "  'agent_obs': {'agent_locs': [[2, 3]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[4, 0], [1, 1], [5, 2], [4, 1]]},\n",
       "  'agent_location': [2, 3]},\n",
       " {'agent_action': 1,\n",
       "  'agent_obs': {'agent_locs': [[3, 3]],\n",
       "   'good_food_locs': [[6, 1], [1, 5]],\n",
       "   'bad_food_locs': [[6, 4], [4, 0], [1, 1], [6, 3], [5, 2], [4, 1]]},\n",
       "  'agent_location': [3, 3]},\n",
       " {'agent_action': 2,\n",
       "  'agent_obs': {'agent_locs': [[4, 3]],\n",
       "   'good_food_locs': [[6, 1], [1, 5]],\n",
       "   'bad_food_locs': [[6, 4], [4, 0], [1, 1], [6, 3], [5, 2], [4, 1]]},\n",
       "  'agent_location': [4, 3]},\n",
       " {'agent_action': 1,\n",
       "  'agent_obs': {'agent_locs': [[4, 4], [1, 7]],\n",
       "   'good_food_locs': [[6, 1], [1, 5]],\n",
       "   'bad_food_locs': [[6, 4], [1, 1], [6, 3], [5, 2], [4, 1]]},\n",
       "  'agent_location': [4, 4]},\n",
       " {'agent_action': 3,\n",
       "  'agent_obs': {'agent_locs': [[5, 4]],\n",
       "   'good_food_locs': [[6, 1]],\n",
       "   'bad_food_locs': [[6, 4], [8, 5], [6, 3], [5, 2], [4, 1]]},\n",
       "  'agent_location': [5, 4]},\n",
       " {'agent_action': 4,\n",
       "  'agent_obs': {'agent_locs': [[4, 4]],\n",
       "   'good_food_locs': [[6, 1], [1, 5]],\n",
       "   'bad_food_locs': [[6, 4], [1, 1], [6, 3], [5, 2], [4, 1]]},\n",
       "  'agent_location': [4, 4]},\n",
       " {'agent_action': 3,\n",
       "  'agent_obs': {'agent_locs': [[4, 3]],\n",
       "   'good_food_locs': [[6, 1], [1, 5]],\n",
       "   'bad_food_locs': [[6, 4], [4, 0], [1, 1], [6, 3], [5, 2], [4, 1]]},\n",
       "  'agent_location': [4, 3]},\n",
       " {'agent_action': 4,\n",
       "  'agent_obs': {'agent_locs': [[3, 3]],\n",
       "   'good_food_locs': [[6, 1], [1, 5]],\n",
       "   'bad_food_locs': [[6, 4], [4, 0], [1, 1], [6, 3], [5, 2], [4, 1]]},\n",
       "  'agent_location': [3, 3]},\n",
       " {'agent_action': 3,\n",
       "  'agent_obs': {'agent_locs': [[3, 2]],\n",
       "   'good_food_locs': [[6, 1], [1, 5]],\n",
       "   'bad_food_locs': [[6, 4], [4, 0], [1, 1], [6, 3], [5, 2], [4, 1]]},\n",
       "  'agent_location': [3, 2]},\n",
       " {'agent_action': 0,\n",
       "  'agent_obs': {'agent_locs': [[2, 2]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[4, 0], [1, 1], [5, 2], [4, 1]]},\n",
       "  'agent_location': [2, 2]},\n",
       " {'agent_action': 3,\n",
       "  'agent_obs': {'agent_locs': [[2, 2]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[4, 0], [1, 1], [5, 2], [4, 1]]},\n",
       "  'agent_location': [2, 2]},\n",
       " {'agent_action': 4,\n",
       "  'agent_obs': {'agent_locs': [[1, 2]],\n",
       "   'good_food_locs': [[1, 5]],\n",
       "   'bad_food_locs': [[4, 0], [1, 1], [4, 1]]},\n",
       "  'agent_location': [1, 2]},\n",
       " {'agent_action': 3,\n",
       "  'agent_obs': {'agent_locs': [[1, 1]],\n",
       "   'good_food_locs': [],\n",
       "   'bad_food_locs': [[4, 0], [4, 1]]},\n",
       "  'agent_location': [1, 1]},\n",
       " {'agent_action': 1,\n",
       "  'agent_obs': {'agent_locs': [[0, 1]],\n",
       "   'good_food_locs': [],\n",
       "   'bad_food_locs': []},\n",
       "  'agent_location': [0, 1]},\n",
       " {'agent_action': 1,\n",
       "  'agent_obs': {'agent_locs': [[1, 1]],\n",
       "   'good_food_locs': [],\n",
       "   'bad_food_locs': [[4, 0], [4, 1]]},\n",
       "  'agent_location': [1, 1]},\n",
       " {'agent_action': 0,\n",
       "  'agent_obs': {'agent_locs': [[2, 1]],\n",
       "   'good_food_locs': [],\n",
       "   'bad_food_locs': [[4, 0], [5, 2], [4, 1]]},\n",
       "  'agent_location': [2, 1]},\n",
       " {'agent_action': 2,\n",
       "  'agent_obs': {'agent_locs': [[2, 1]],\n",
       "   'good_food_locs': [],\n",
       "   'bad_food_locs': [[4, 0], [5, 2], [4, 1]]},\n",
       "  'agent_location': [2, 1]},\n",
       " {'agent_action': 4,\n",
       "  'agent_obs': {'agent_locs': [[2, 2], [1, 5]],\n",
       "   'good_food_locs': [],\n",
       "   'bad_food_locs': [[4, 0], [5, 2], [4, 1]]},\n",
       "  'agent_location': [2, 2]},\n",
       " {'agent_action': 1,\n",
       "  'agent_obs': {'agent_locs': [[2, 1]],\n",
       "   'good_food_locs': [],\n",
       "   'bad_food_locs': [[4, 0], [5, 2], [4, 1]]},\n",
       "  'agent_location': [2, 1]},\n",
       " {'agent_action': 1,\n",
       "  'agent_obs': {'agent_locs': [[3, 1]],\n",
       "   'good_food_locs': [[6, 1]],\n",
       "   'bad_food_locs': [[6, 4], [4, 0], [6, 3], [5, 2], [4, 1]]},\n",
       "  'agent_location': [3, 1]},\n",
       " {'agent_action': 1,\n",
       "  'agent_obs': {'agent_locs': [[4, 1]],\n",
       "   'good_food_locs': [[6, 1]],\n",
       "   'bad_food_locs': [[6, 4], [4, 0], [6, 3], [5, 2]]},\n",
       "  'agent_location': [4, 1]},\n",
       " {'agent_action': 2,\n",
       "  'agent_obs': {'agent_locs': [[5, 1]],\n",
       "   'good_food_locs': [[6, 1]],\n",
       "   'bad_food_locs': [[6, 4], [4, 0], [6, 3], [5, 2]]},\n",
       "  'agent_location': [5, 1]},\n",
       " {'agent_action': 3,\n",
       "  'agent_obs': {'agent_locs': [[5, 2]],\n",
       "   'good_food_locs': [[6, 1]],\n",
       "   'bad_food_locs': [[6, 4], [4, 0], [8, 5], [6, 3]]},\n",
       "  'agent_location': [5, 2]},\n",
       " {'agent_action': 2,\n",
       "  'agent_obs': {'agent_locs': [[4, 2]],\n",
       "   'good_food_locs': [[6, 1]],\n",
       "   'bad_food_locs': [[6, 4], [4, 0], [6, 3]]},\n",
       "  'agent_location': [4, 2]},\n",
       " {'agent_action': 2,\n",
       "  'agent_obs': {'agent_locs': [[4, 3], [1, 6]],\n",
       "   'good_food_locs': [[6, 1]],\n",
       "   'bad_food_locs': [[6, 4], [4, 0], [6, 3]]},\n",
       "  'agent_location': [4, 3]},\n",
       " {'agent_action': 0,\n",
       "  'agent_obs': {'agent_locs': [[4, 4], [2, 7], [1, 5]],\n",
       "   'good_food_locs': [[6, 1]],\n",
       "   'bad_food_locs': [[6, 4], [6, 3]]},\n",
       "  'agent_location': [4, 4]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.agents[0].memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}