{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABD2\n",
    "\n",
    "Wij gaan tijdens deze opdracht een food-collector simulatie bouwen.\n",
    "In deze simulatie is het doel van de agents om zo veel mogelijk groen eten op te eten, terwijl ze rood eten vermijden.\n",
    "We gaan deze simulatie grid-based maken. \n",
    "\n",
    "We maken gebruik van de gymnasium API: https://gymnasium.farama.org/\n",
    "\n",
    "Ter visualisatie gebruiken we pygame.\n",
    "\n",
    "\n",
    "\n",
    "### Simulation properties:\n",
    "We beginnen in principe met een grid van 128x128, maar dit kan uitgebreid worden. \n",
    "We zullen de implementatie zoveel mogelijk scalable en aanpasbaar implementeren, door hyperparameters aan te maken voor alle belangrijke properties.\n",
    "\n",
    "- Number of agents\n",
    "- Grid size (default 128x128)\n",
    "- Good food to total square ratio\n",
    "- Good food spawning pattern (maybe)\n",
    "- Bad food to total square ratio\n",
    "- Bad food spawning pattern (maybe)\n",
    "- Episode duration\n",
    "\n",
    "### Agent properties:\n",
    "Actions: up, down, left, right, wait\n",
    "\n",
    "Perception: full information (knows coordinates of other agents, good food, and bad food)\n",
    "\n",
    "Agent rules: not yet specified\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pygame\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import random\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "outputs": [],
   "source": [
    "class agent():\n",
    "    def __init__(self):\n",
    "        self.location = [None, None]\n",
    "        self.points = 0\n",
    "        self.vision_range = 10\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([0, 0]),\n",
    "            1: np.array([1, 0]),\n",
    "            2: np.array([0, 1]),\n",
    "            3: np.array([-1, 0]),\n",
    "            4: np.array([0, -1])\n",
    "        }\n",
    "\n",
    "    def move(self, direction, grid_size):\n",
    "        new_location = self.location + direction\n",
    "        self.location = list(new_location)\n",
    "\n",
    "    def clip_vision(self, obs):\n",
    "\n",
    "        clipped_obs = {}\n",
    "\n",
    "        for k in obs.keys():\n",
    "\n",
    "            clipped_obs[k] = [x for x in obs[k]\n",
    "                      if abs(self.location[0] - x[0]) <= self.vision_range\n",
    "                      or abs(self.location[1] - x[1]) <= self.vision_range\n",
    "                     ]\n",
    "\n",
    "        return clipped_obs\n",
    "\n",
    "    def pick_action(self,obs, grid_size):\n",
    "\n",
    "\n",
    "        # clip the observation to the agents vision\n",
    "        obs = self.clip_vision(obs)\n",
    "\n",
    "        viable_actions = list(self._action_to_direction.keys())\n",
    "\n",
    "        other_agent_locations = [x for x in obs['agent_locs'] if x != self.location]\n",
    "\n",
    "        # Rule 1: agents can't move to a space occupied by another agent\n",
    "        viable_actions = [v for v in viable_actions if list(self.location +  self._action_to_direction[v]) not in other_agent_locations]\n",
    "        # Rule 2: agents can't move out of bounds\n",
    "        viable_actions = [v for v in viable_actions\n",
    "                          if list(self.location +  self._action_to_direction[v])[0] >= 0\n",
    "                          and list(self.location +  self._action_to_direction[v])[1] >= 0\n",
    "                          and list(self.location +  self._action_to_direction[v])[0] < grid_size\n",
    "                          and list(self.location +  self._action_to_direction[v])[1] < grid_size]\n",
    "\n",
    "\n",
    "        return random.choice(viable_actions)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "outputs": [],
   "source": [
    "class foodCollectorEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", None], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self, render_mode=None, grid_size=128, game_duration=200, agents=1, good_food_ratio=0.1,\n",
    "                 bad_food_ratio=0.1):\n",
    "        self.grid_size = grid_size\n",
    "        self.window_size = 720\n",
    "        self.game_duration = game_duration * agents\n",
    "        self.current_step = 0\n",
    "        self.agents = [agent() for _ in range(agents)]\n",
    "        self.good_food_ratio = good_food_ratio\n",
    "        self.bad_food_ratio = bad_food_ratio\n",
    "        self.good_food_points = 5\n",
    "        self.bad_food_points = -1\n",
    "        self.render_mode = render_mode\n",
    "        self.window = None\n",
    "\n",
    "\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'agent_locs': spaces.Sequence(spaces.MultiDiscrete([self.grid_size - 1, self.grid_size - 1])),\n",
    "            'good_food_locs': spaces.Sequence(spaces.MultiDiscrete([self.grid_size - 1, self.grid_size - 1])),\n",
    "            'bad_food_locs': spaces.Sequence(spaces.MultiDiscrete([self.grid_size - 1, self.grid_size - 1])),\n",
    "        })\n",
    "\n",
    "        self.action_space = spaces.Sequence(spaces.Tuple((spaces.MultiDiscrete(len(self.agents)) ,spaces.MultiDiscrete(5) )))\n",
    "\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([0, 0]),\n",
    "            1: np.array([1, 0]),\n",
    "            2: np.array([0, 1]),\n",
    "            3: np.array([-1, 0]),\n",
    "            4: np.array([0, -1])\n",
    "        }\n",
    "\n",
    "        self.good_food_locations = []\n",
    "        self.bad_food_locations = []\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return {\n",
    "            \"agent_locs\": [agent.location for agent in self.agents],\n",
    "            \"good_food_locs\": self.good_food_locs,\n",
    "            \"bad_food_locs\": self.bad_food_locs\n",
    "        }\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        self.agent_locs = []\n",
    "        self.good_food_locs = []\n",
    "        self.bad_food_locs = []\n",
    "\n",
    "\n",
    "        # place agents\n",
    "        while True:\n",
    "            if len(self.agent_locs) >= len(self.agents):\n",
    "                break\n",
    "            loc = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]\n",
    "            if loc not in self.agent_locs:\n",
    "                self.agent_locs.append(loc)\n",
    "\n",
    "\n",
    "        # place good food\n",
    "        while True:\n",
    "            if len(self.good_food_locs) >= round(self.good_food_ratio * self.grid_size * self.grid_size):\n",
    "                break\n",
    "            loc = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]\n",
    "            if loc not in self.agent_locs and loc not in self.good_food_locs and loc not in self.bad_food_locs:\n",
    "                self.good_food_locs.append(loc)\n",
    "\n",
    "        #place bad food\n",
    "        while True:\n",
    "            if len(self.bad_food_locs) >= round(self.bad_food_ratio * self.grid_size * self.grid_size):\n",
    "                break\n",
    "            loc = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]\n",
    "            if loc not in self.agent_locs and loc not in self.good_food_locs and loc not in self.bad_food_locs:\n",
    "                self.bad_food_locs.append(loc)\n",
    "\n",
    "        for i, agent in enumerate(self.agents):\n",
    "            agent.location = self.agent_locs[i]\n",
    "\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        info = {\"agent_points\": [agent.points for agent in self.agents]}\n",
    "\n",
    "        return observation, info\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        direction = self._action_to_direction[action[1]]\n",
    "\n",
    "        self.agents[action[0]].move(direction, self.grid_size)\n",
    "\n",
    "        if self.agents[action[0]].location in self.good_food_locs:\n",
    "            self.good_food_locs.remove(self.agents[action[0]].location)\n",
    "            self.agents[action[0]].points += self.good_food_points\n",
    "\n",
    "        if self.agents[action[0]].location in self.bad_food_locs:\n",
    "            self.bad_food_locs.remove(self.agents[action[0]].location)\n",
    "            self.agents[action[0]].points += self.bad_food_points\n",
    "\n",
    "        terminated = self.current_step >= self.game_duration\n",
    "        reward = 0 # niet relevant voor nu\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "        info = {\"agent_points\": [agent.points for agent in self.agents]}\n",
    "\n",
    "        self.current_step += 1\n",
    "        #time.sleep(0.01)\n",
    "\n",
    "        return observation, reward, terminated, info\n",
    "\n",
    "    def _is_empty(self, loc):\n",
    "\n",
    "        for agent in self.agents:\n",
    "            if sorted(agent.location) == sorted(loc):\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == \"rgb_array\":\n",
    "            return self._render_frame()\n",
    "\n",
    "    def _render_frame(self):\n",
    "        pygame.font.init()\n",
    "        font = pygame.font.Font(None, 24)\n",
    "        scoreboard_width = 0.2\n",
    "\n",
    "        if self.window is None and self.render_mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.window = pygame.display.set_mode(\n",
    "                (self.window_size + self.window_size * scoreboard_width, self.window_size)\n",
    "            )\n",
    "\n",
    "        canvas = pygame.Surface((self.window_size + self.window_size * scoreboard_width, self.window_size))\n",
    "        canvas.fill((204, 255, 229))\n",
    "        pix_square_size = (\n",
    "                self.window_size / self.grid_size\n",
    "        )\n",
    "\n",
    "\n",
    "        for i, agent in enumerate(self.agents):\n",
    "            deer_image = pygame.image.load(\"deer.png\").convert_alpha()\n",
    "            deer_image = pygame.transform.scale(deer_image, (pix_square_size, pix_square_size))\n",
    "            canvas.blit(deer_image, (agent.location[0] * pix_square_size, (self.grid_size - 1 - agent.location[1]) * pix_square_size))\n",
    "\n",
    "            #try to draw vision_range, a bit awkward imo\n",
    "            fov = pygame.Surface((pix_square_size * agent.vision_range, pix_square_size * agent.vision_range))\n",
    "            fov.set_alpha(128)\n",
    "            fov.fill((137,137,137))\n",
    "            canvas.blit(fov, (((agent.location[0] * pix_square_size)-0.5*agent.vision_range*pix_square_size), ((self.grid_size - 1 - agent.location[1]) * pix_square_size)-0.5*agent.vision_range*pix_square_size))\n",
    "\n",
    "            scoreboard_bg = pygame.Surface((self.window_size*scoreboard_width,self.window_size+self.window_size*scoreboard_width))\n",
    "            scoreboard_bg.fill((255, 255, 255))\n",
    "            scoreboard_bg.set_alpha(255)\n",
    "\n",
    "            canvas.blit(scoreboard_bg, (self.window_size, 0))\n",
    "            score_text = font.render(f\"{i}\", True, \"white\")\n",
    "            canvas.blit(score_text, (agent.location[0] * pix_square_size, (self.grid_size - 1 - agent.location[1]) * pix_square_size))\n",
    "\n",
    "\n",
    "\n",
    "        for gfl in self.good_food_locs:\n",
    "            good_food_image = pygame.image.load(\"plant.png\").convert_alpha()\n",
    "            good_food_image = pygame.transform.scale(good_food_image, (pix_square_size, pix_square_size))\n",
    "            canvas.blit(good_food_image, (gfl[0] * pix_square_size, (self.grid_size - 1 - gfl[1]) * pix_square_size))\n",
    "\n",
    "        for bfl in self.bad_food_locs:\n",
    "            bad_food_image = pygame.image.load(\"evil_plant.png\").convert_alpha()\n",
    "            bad_food_image = pygame.transform.scale(bad_food_image, (pix_square_size, pix_square_size))\n",
    "            canvas.blit(bad_food_image, (bfl[0] * pix_square_size, (self.grid_size - 1 - bfl[1]) * pix_square_size))\n",
    "\n",
    "        for x in range(self.grid_size + 1):\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                color=0,\n",
    "                start_pos=(0, pix_square_size * x),\n",
    "                end_pos=(self.window_size, pix_square_size * x),\n",
    "                width=1,\n",
    "            )\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                color=0,\n",
    "                start_pos=(pix_square_size * x, 0),\n",
    "                end_pos=(pix_square_size * x, self.window_size),\n",
    "                width=1,\n",
    "            )\n",
    "\n",
    "        for i, agent in enumerate(self.agents):\n",
    "\n",
    "            score_text = font.render(f'Agent {i} | {agent.points}', True, \"black\")\n",
    "            canvas.blit(score_text, (self.window_size + 10 , 10 + (i*50)))\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "\n",
    "            self.window.blit(canvas, canvas.get_rect())\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "\n",
    "            #self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        else:\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
    "            )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "outputs": [],
   "source": [
    "env = foodCollectorEnv(render_mode=\"human\", grid_size=32, game_duration=500, agents=10, good_food_ratio=0.02,\n",
    "                       bad_food_ratio=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "outputs": [
    {
     "data": {
      "text/plain": "({'agent_locs': [[31, 27],\n   [11, 26],\n   [1, 21],\n   [25, 14],\n   [11, 15],\n   [29, 16],\n   [8, 24],\n   [23, 17],\n   [25, 25],\n   [5, 24]],\n  'good_food_locs': [[27, 29],\n   [30, 21],\n   [18, 26],\n   [29, 0],\n   [28, 23],\n   [25, 13],\n   [8, 14],\n   [0, 11],\n   [3, 11],\n   [16, 2],\n   [7, 11],\n   [30, 22],\n   [1, 30],\n   [14, 19],\n   [21, 5],\n   [24, 13],\n   [25, 5],\n   [15, 1],\n   [16, 25],\n   [26, 26]],\n  'bad_food_locs': [[20, 3],\n   [13, 24],\n   [16, 26],\n   [28, 27],\n   [1, 0],\n   [29, 19],\n   [21, 26],\n   [7, 13],\n   [19, 1],\n   [10, 1],\n   [24, 1],\n   [19, 10],\n   [13, 30],\n   [28, 30],\n   [15, 21],\n   [15, 24],\n   [17, 5],\n   [16, 30],\n   [7, 7],\n   [28, 1],\n   [31, 26],\n   [31, 3],\n   [16, 8],\n   [13, 31],\n   [14, 9],\n   [21, 0],\n   [4, 13],\n   [11, 30],\n   [14, 16],\n   [3, 28],\n   [22, 9],\n   [8, 12],\n   [8, 15],\n   [6, 15],\n   [2, 16],\n   [29, 29],\n   [12, 0],\n   [0, 23],\n   [19, 15],\n   [27, 0],\n   [16, 6],\n   [8, 16],\n   [24, 8],\n   [7, 27],\n   [27, 11],\n   [8, 25],\n   [12, 2],\n   [30, 20],\n   [14, 31],\n   [4, 12],\n   [19, 31],\n   [3, 18],\n   [2, 9],\n   [20, 10],\n   [30, 30],\n   [5, 4],\n   [25, 17],\n   [7, 17],\n   [15, 11],\n   [28, 10],\n   [10, 23],\n   [1, 10],\n   [28, 0],\n   [7, 30],\n   [12, 31],\n   [8, 28],\n   [19, 17],\n   [15, 25],\n   [28, 29],\n   [5, 19],\n   [11, 4],\n   [20, 9],\n   [28, 9],\n   [0, 28],\n   [14, 1],\n   [11, 10],\n   [22, 31],\n   [3, 24],\n   [6, 16],\n   [15, 15],\n   [0, 6],\n   [21, 28],\n   [5, 7],\n   [18, 29],\n   [29, 27],\n   [22, 5],\n   [27, 6],\n   [3, 26],\n   [30, 26],\n   [24, 15],\n   [25, 11],\n   [18, 0],\n   [3, 3],\n   [1, 7],\n   [0, 13],\n   [5, 2],\n   [14, 2],\n   [20, 7],\n   [27, 20],\n   [6, 7],\n   [28, 26],\n   [22, 11],\n   [27, 2],\n   [20, 30],\n   [21, 19],\n   [12, 26],\n   [7, 2],\n   [4, 0],\n   [18, 3],\n   [14, 11],\n   [18, 28],\n   [7, 5],\n   [11, 0],\n   [25, 22],\n   [21, 7],\n   [29, 25],\n   [14, 23],\n   [17, 21],\n   [12, 21],\n   [0, 26],\n   [20, 25],\n   [26, 23],\n   [0, 20],\n   [4, 5],\n   [18, 20],\n   [14, 20],\n   [7, 22],\n   [10, 17],\n   [19, 28],\n   [2, 22],\n   [4, 18],\n   [1, 24],\n   [30, 6],\n   [28, 11],\n   [7, 4],\n   [11, 5],\n   [1, 13],\n   [26, 14],\n   [21, 6],\n   [11, 20],\n   [20, 31],\n   [6, 4],\n   [14, 21],\n   [27, 19],\n   [17, 31],\n   [28, 18],\n   [6, 5],\n   [5, 8],\n   [9, 23],\n   [19, 30],\n   [3, 4],\n   [27, 26],\n   [20, 16],\n   [23, 9],\n   [9, 27],\n   [8, 9],\n   [5, 9],\n   [24, 29],\n   [26, 28],\n   [2, 11],\n   [29, 18],\n   [0, 2],\n   [8, 29],\n   [2, 8],\n   [13, 14],\n   [5, 23],\n   [30, 25],\n   [31, 29],\n   [31, 10],\n   [26, 22],\n   [12, 12],\n   [15, 5],\n   [0, 21],\n   [29, 4],\n   [10, 22],\n   [5, 1],\n   [2, 2],\n   [8, 13],\n   [16, 15],\n   [31, 18],\n   [12, 17],\n   [28, 17],\n   [17, 24],\n   [8, 1],\n   [16, 28],\n   [2, 10],\n   [31, 23],\n   [14, 28],\n   [22, 7],\n   [8, 0],\n   [9, 4],\n   [0, 4],\n   [25, 2],\n   [27, 8],\n   [17, 28],\n   [20, 19],\n   [29, 3],\n   [3, 13],\n   [4, 1],\n   [3, 2],\n   [14, 25],\n   [4, 8],\n   [18, 7],\n   [21, 18],\n   [4, 7]]},\n {'agent_points': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]})"
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-530-89fc914e0488>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m         \u001B[0maction\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0menv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0magents\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpick_action\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobservation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0menv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgrid_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m         \u001B[0mobservation\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mterminated\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minfo\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0menv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0maction\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mterminated\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-527-91f2d80770c4>\u001B[0m in \u001B[0;36mstep\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m    108\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    109\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrender_mode\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"human\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 110\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_render_frame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    111\u001B[0m         \u001B[0minfo\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m\"agent_points\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0magent\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpoints\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0magent\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0magents\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-527-91f2d80770c4>\u001B[0m in \u001B[0;36m_render_frame\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    173\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    174\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mbfl\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbad_food_locs\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 175\u001B[1;33m             \u001B[0mbad_food_image\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpygame\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"evil_plant.png\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconvert_alpha\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    176\u001B[0m             \u001B[0mbad_food_image\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpygame\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mscale\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbad_food_image\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mpix_square_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpix_square_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    177\u001B[0m             \u001B[0mcanvas\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mblit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbad_food_image\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mbfl\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mpix_square_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgrid_size\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mbfl\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mpix_square_size\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "observation = env._get_obs()\n",
    "while True:\n",
    "    \n",
    "    for i in range(len(env.agents)):\n",
    "        \n",
    "        action = [i,env.agents[i].pick_action(observation, env.grid_size)]\n",
    "        observation, reward, terminated, info = env.step(action)\n",
    "\n",
    "    if terminated:\n",
    "        break\n",
    "pygame.quit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(info)\n",
    "np.argmax(info['agent_points'])\n",
    "print(f\"Agent {np.argmax(info['agent_points'])} wins the game with {max(info['agent_points'])} points\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
