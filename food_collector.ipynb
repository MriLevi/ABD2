{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABD2\n",
    "\n",
    "Wij gaan tijdens deze opdracht een food-collector simulatie bouwen.\n",
    "In deze simulatie is het doel van de agents om zo veel mogelijk groen eten op te eten, terwijl ze rood eten vermijden.\n",
    "We gaan deze simulatie grid-based maken. \n",
    "\n",
    "We maken gebruik van de gymnasium API: https://gymnasium.farama.org/\n",
    "\n",
    "Ter visualisatie gebruiken we pygame.\n",
    "\n",
    "\n",
    "### Simulation properties:\n",
    "We beginnen in principe met een grid van 128x128, maar dit kan uitgebreid worden. \n",
    "We zullen de implementatie zoveel mogelijk scalable en aanpasbaar implementeren, door hyperparameters aan te maken voor alle belangrijke properties.\n",
    "\n",
    "- Number of agents\n",
    "- Grid size (default 128x128)\n",
    "- Good food to total square ratio\n",
    "- Good food spawning pattern (maybe)\n",
    "- Bad food to total square ratio\n",
    "- Bad food spawning pattern (maybe)\n",
    "- Episode duration\n",
    "\n",
    "### Agent properties:\n",
    "Actions: up, down, left, right, wait\n",
    "Perception: full information (knows coordinates of other agents, good food, and bad food)\n",
    "Agent rules: not yet specified\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.3.dev8 (SDL 2.0.22, Python 3.10.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pygame\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import random\n",
    "import time\n",
    "import tcod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class agent():\n",
    "    def __init__(self):\n",
    "        self.location = [None, None]\n",
    "        self.points = 0\n",
    "        self.vision_range = 3\n",
    "        self.memory = []\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([0, 0]),\n",
    "            1: np.array([1, 0]),\n",
    "            2: np.array([0, 1]),\n",
    "            3: np.array([-1, 0]),\n",
    "            4: np.array([0, -1])\n",
    "        }\n",
    "        self.path = []\n",
    "        self.q_dict = {}\n",
    "\n",
    "    def move(self, direction):\n",
    "        \"\"\"move an agent into a specific direction\"\"\"\n",
    "        \n",
    "        new_location = self.location + direction\n",
    "        self.location = list(new_location)\n",
    "        \n",
    "\n",
    "    def clip_vision(self, obs):\n",
    "        \"\"\"clip the observation of the agent to the vision_range\"\"\"\n",
    "\n",
    "        clipped_obs = {}\n",
    "\n",
    "        for k in obs.keys():\n",
    "\n",
    "            clipped_obs[k] = [x for x in obs[k]\n",
    "                      if abs(self.location[0] - x[0]) <= self.vision_range\n",
    "                      and abs(self.location[1] - x[1]) <= self.vision_range\n",
    "                     ]\n",
    "\n",
    "        return clipped_obs\n",
    "    \n",
    "    def get_best_move(self, obs, grid_size):\n",
    "        \"\"\"return the best action an agent can take, calculated with a*; returns None if no good food in vision range\"\"\"\n",
    "        \n",
    "        cost = np.full((self.vision_range*2 + 1, self.vision_range*2 + 1),2)\n",
    "        \n",
    "        for k in obs.keys():\n",
    "            \n",
    "            new_coords = [[x-self.location[0] + self.vision_range,y-self.location[1]+ self.vision_range]  for x,y in obs[k]]\n",
    "            \n",
    "            if k == 'bad_food_locs':\n",
    "                for x in new_coords:\n",
    "                    cost[x[0]][x[1]] = 10\n",
    "                    # it can be worth it for the agent to cross bad food to get to good food with the current point assignment (-1,5) if it's the only path available\n",
    "            if k == 'good_food_locs':\n",
    "                for x in new_coords:\n",
    "                    cost[x[0]][x[1]] = 1\n",
    "            if k == 'agent_locs':\n",
    "                for x in new_coords:\n",
    "                    cost[x[0]][x[1]] = 0\n",
    "            \n",
    "            # out of bounds squares get value 0\n",
    "            for x in np.argwhere(cost != None):\n",
    "                converted_coord = (np.array(x) - np.array([self.vision_range,self.vision_range]) + self.location)\n",
    "                if converted_coord[0] > grid_size -1 or converted_coord[0] < 0 or converted_coord[1] > grid_size -1 or converted_coord[1] < 0:\n",
    "                    cost[x[0]][x[1]] = 0\n",
    "                    \n",
    "                \n",
    "        good_food_converted_locs = list(zip(*np.where(cost == 1)))\n",
    "        #print(np.rot90(cost, k=1, axes=(0, 1)))\n",
    "    \n",
    "        cost = cost.astype(np.int8) #changed type, now it works\n",
    "        graph = tcod.path.SimpleGraph(cost = cost, cardinal =1, diagonal = 0)\n",
    "        pf = tcod.path.Pathfinder(graph)\n",
    "        pf.add_root((self.vision_range, self.vision_range))\n",
    "        pf.resolve()\n",
    "        \n",
    "           \n",
    "        best_move = None\n",
    "        \n",
    "        # calculate the best paths to all available good_food in vision_range\n",
    "        paths = [pf.path_to(cl)[1:].tolist() for cl in good_food_converted_locs if len(pf.path_to(cl)[1:].tolist()) != 0]\n",
    "\n",
    "        self.path = []\n",
    "        if len(paths) > 0:\n",
    "            shortest_path_index = np.argmin([len(x) for x in paths])\n",
    "            for x in paths[shortest_path_index]:\n",
    "                self.path.append(list(np.array(x) - np.array([-self.location[0] + self.vision_range,-self.location[1]+ self.vision_range])))\n",
    "            best_move = list(np.array(paths[shortest_path_index][0]) - np.array([self.vision_range, self.vision_range]))\n",
    "            best_move = [x[0] for x in list(self._action_to_direction.items()) if x[1][0] == best_move[0] and x[1][1] == best_move[1]][0]\n",
    "            \n",
    "            return best_move\n",
    "        \n",
    "        return None\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "    def pick_action(self,obs, grid_size):\n",
    "        \n",
    "                \n",
    "        best_move = self.get_best_move(obs, grid_size)\n",
    "\n",
    "        viable_actions = list(self._action_to_direction.keys())\n",
    "\n",
    "        other_agent_locations = [x for x in obs['agent_locs'] if x != self.location]\n",
    "\n",
    "        # Rule 1: agents can't move to a space occupied by another agent\n",
    "        viable_actions = [v for v in viable_actions if list(self.location +  self._action_to_direction[v]) not in other_agent_locations]\n",
    "        # Rule 2: agents can't move out of bounds\n",
    "        viable_actions = [v for v in viable_actions\n",
    "                          if list(self.location +  self._action_to_direction[v])[0] >= 0\n",
    "                          and list(self.location +  self._action_to_direction[v])[1] >= 0\n",
    "                          and list(self.location +  self._action_to_direction[v])[0] < grid_size\n",
    "                          and list(self.location +  self._action_to_direction[v])[1] < grid_size]\n",
    "        \n",
    "\n",
    "        #Rule 3: never step on bad food (while exploring)\n",
    "        viable_actions = [k for k,v in {v:list(self.location + self._action_to_direction[v]) for v in viable_actions}.items()\n",
    "                          if v not in obs['bad_food_locs']]\n",
    "    \n",
    "     \n",
    "        \n",
    "        #Rule 4: prioritize undiscovered squares over discovered squares without good food in vision range\n",
    "        viable_actions_higher_prio = [k for k,v in {v:list(self.location + self._action_to_direction[v]) for v in viable_actions}.items()\n",
    "                          if v not in [x['agent_location'] for x in self.memory if len(x['agent_obs']['good_food_locs'])==0]]\n",
    "         \n",
    "            \n",
    "        # unstuck the agent if it gets caught in a loop\n",
    "        action_history = [x['agent_action'] for x in self.memory][-10:]\n",
    "        if len(action_history) >= 10:\n",
    "            if len(list(set(action_history))) == 2:\n",
    "                if len(list(set([action_history[l] for l in range(len(action_history)) if l % 2 == 0]))) == 1 and len(list(set([action_history[l] for l in range(len(action_history)) if l % 2 == 1]))) == 1:\n",
    "                   \n",
    "                    return random.choice(viable_actions)\n",
    "    \n",
    "        \n",
    "        if best_move == None:\n",
    "            if len(viable_actions_higher_prio) > 0:\n",
    "                action = random.choice(viable_actions_higher_prio)\n",
    "            else:\n",
    "                action = random.choice(viable_actions)\n",
    "\n",
    "        else:\n",
    "\n",
    "            action = best_move\n",
    "        \n",
    "        return action\n",
    "    \n",
    "        \n",
    "        \n",
    "    def run(self, obs, grid_size):\n",
    "        \n",
    "        # clip the observation to the agents vision\n",
    "        clipped_obs = self.clip_vision(obs)\n",
    "        \n",
    "        # decide which action to take based on the previous observation\n",
    "        action = self.pick_action(clipped_obs, grid_size)\n",
    "        \n",
    "        # append the new information to the agent's memory\n",
    "        self.memory.append({'agent_action':action, \"agent_obs\":clipped_obs, \"agent_location\":self.location})\n",
    "        \n",
    "        \n",
    "        return action\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class foodCollectorEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", None], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self, render_mode=None, grid_size=128, game_duration=200, agents=1, good_food_ratio=0.1,\n",
    "                 bad_food_ratio=0.1):\n",
    "        self.grid_size = grid_size\n",
    "        self.window_size = 1028\n",
    "        self.game_duration = game_duration * agents\n",
    "        self.current_step = 0\n",
    "        self.agents = [agent() for _ in range(agents)]\n",
    "        self.good_food_ratio = good_food_ratio\n",
    "        self.bad_food_ratio = bad_food_ratio\n",
    "        self.good_food_points = 5\n",
    "        self.bad_food_points = -1\n",
    "        self.render_mode = render_mode\n",
    "        self.window = None\n",
    "        self.grid = np.ones((self.grid_size, self.grid_size))\n",
    "\n",
    "\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'agent_locs': spaces.Sequence(spaces.MultiDiscrete([self.grid_size - 1, self.grid_size - 1])),\n",
    "            'good_food_locs': spaces.Sequence(spaces.MultiDiscrete([self.grid_size - 1, self.grid_size - 1])),\n",
    "            'bad_food_locs': spaces.Sequence(spaces.MultiDiscrete([self.grid_size - 1, self.grid_size - 1])),\n",
    "        })\n",
    "\n",
    "        self.action_space = spaces.Sequence(spaces.MultiDiscrete(5))\n",
    "\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([0, 0]),\n",
    "            1: np.array([1, 0]),\n",
    "            2: np.array([0, 1]),\n",
    "            3: np.array([-1, 0]),\n",
    "            4: np.array([0, -1])\n",
    "        }\n",
    "\n",
    "        self.good_food_locations = []\n",
    "        self.bad_food_locations = []\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return {\n",
    "            \"agent_locs\": [agent.location for agent in self.agents],\n",
    "            \"good_food_locs\": self.good_food_locs,\n",
    "            \"bad_food_locs\": self.bad_food_locs\n",
    "        }\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        self.agent_locs = []\n",
    "        self.good_food_locs = []\n",
    "        self.bad_food_locs = []\n",
    "\n",
    "\n",
    "        # place agents\n",
    "        while True:\n",
    "            if len(self.agent_locs) >= len(self.agents):\n",
    "                break\n",
    "            loc = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]\n",
    "            if loc not in self.agent_locs:\n",
    "                self.agent_locs.append(loc)\n",
    "\n",
    "\n",
    "        # place good food\n",
    "        while True:\n",
    "            if len(self.good_food_locs) >= round(self.good_food_ratio * self.grid_size * self.grid_size):\n",
    "                break\n",
    "            loc = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]\n",
    "            if loc not in self.agent_locs and loc not in self.good_food_locs and loc not in self.bad_food_locs:\n",
    "                self.good_food_locs.append(loc)\n",
    "\n",
    "        #place bad food\n",
    "        while True:\n",
    "            if len(self.bad_food_locs) >= round(self.bad_food_ratio * self.grid_size * self.grid_size):\n",
    "                break\n",
    "            loc = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]\n",
    "            if loc not in self.agent_locs and loc not in self.good_food_locs and loc not in self.bad_food_locs:\n",
    "                self.bad_food_locs.append(loc)\n",
    "\n",
    "        for i, agent in enumerate(self.agents):\n",
    "            agent.location = self.agent_locs[i]\n",
    "        \n",
    "        observation = self._get_obs()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        info = {\"agent_points\": [agent.points for agent in self.agents]}\n",
    "\n",
    "\n",
    "\n",
    "        return observation, info\n",
    "\n",
    "    def step(self, action, agent_index):\n",
    "        \n",
    "        direction = self._action_to_direction[action[0]]\n",
    "        \n",
    "        self.agents[agent_index].move(direction)\n",
    "\n",
    "        if self.agents[agent_index].location in self.good_food_locs:\n",
    "            self.good_food_locs.remove(self.agents[agent_index].location)\n",
    "            self.agents[agent_index].points += self.good_food_points\n",
    "\n",
    "        if self.agents[agent_index].location in self.bad_food_locs:\n",
    "            self.bad_food_locs.remove(self.agents[agent_index].location)\n",
    "            self.agents[agent_index].points += self.bad_food_points\n",
    "\n",
    "        terminated = self.current_step >= self.game_duration or (len(self._get_obs()['good_food_locs']) == 0 and self.current_step > 0)\n",
    "        reward = 0 # niet relevant voor nu\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "        info = {\"agent_points\": [agent.points for agent in self.agents]}\n",
    "\n",
    "        self.current_step += 1\n",
    "\n",
    "        return observation, reward, terminated, info\n",
    "\n",
    "    def _is_empty(self, loc):\n",
    "\n",
    "        for agent in self.agents:\n",
    "            if sorted(agent.location) == sorted(loc):\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == \"rgb_array\":\n",
    "            return self._render_frame()\n",
    "\n",
    "    def _render_frame(self):\n",
    "        pygame.font.init()\n",
    "        font = pygame.font.Font(None, 24)\n",
    "        scoreboard_width = 0.2\n",
    "\n",
    "        if self.window is None and self.render_mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.window = pygame.display.set_mode(\n",
    "                (self.window_size + self.window_size * scoreboard_width, self.window_size)\n",
    "            )\n",
    "\n",
    "        canvas = pygame.Surface((self.window_size + self.window_size * scoreboard_width, self.window_size))\n",
    "        canvas.fill((204, 255, 229))\n",
    "        pix_square_size = (\n",
    "                self.window_size / self.grid_size\n",
    "        )\n",
    "\n",
    "        #draw the background for the scoreboard\n",
    "        scoreboard_bg = pygame.Surface((self.window_size*scoreboard_width,self.window_size+self.window_size*scoreboard_width))\n",
    "        scoreboard_bg.fill((255, 255, 255))\n",
    "        scoreboard_bg.set_alpha(255)\n",
    "        canvas.blit(scoreboard_bg, (self.window_size, 0))\n",
    "            \n",
    "        for i, agent in enumerate(self.agents):\n",
    "            #draw agent picture\n",
    "            deer_image = pygame.image.load(\"deer.png\").convert_alpha()\n",
    "            deer_image = pygame.transform.scale(deer_image, (pix_square_size, pix_square_size))\n",
    "            canvas.blit(deer_image, (agent.location[0] * pix_square_size, (self.grid_size - 1 - agent.location[1]) * pix_square_size))\n",
    "\n",
    "            #try to draw vision_range, a bit awkward imo\n",
    "            fov = pygame.Surface((pix_square_size * (agent.vision_range*2+1), pix_square_size * (agent.vision_range*2+1)))\n",
    "            fov.set_alpha(128)\n",
    "            fov.fill((137,137,137))\n",
    "            canvas.blit(fov, ((agent.location[0] * pix_square_size)-pix_square_size*agent.vision_range, ((self.grid_size - 1 - agent.location[1]) * pix_square_size) - pix_square_size * agent.vision_range))\n",
    "\n",
    "            \n",
    "            score_text = font.render(f'Agent {i} | {agent.points}', True, \"black\")\n",
    "            canvas.blit(score_text, (self.window_size + 10 , 10 + (i*50)))\n",
    "            \n",
    "            score_text = font.render(f\"{i}\", True, \"white\")\n",
    "            canvas.blit(score_text, (agent.location[0] * pix_square_size, (self.grid_size - 1 - agent.location[1]) * pix_square_size))\n",
    "            \n",
    "\n",
    "            #path to good food\n",
    "            if len(agent.path) > 1:\n",
    "                for coord in agent.path[1:]:\n",
    "                    #draw the path\n",
    "                    path = pygame.Surface((pix_square_size, pix_square_size))\n",
    "                    path.set_alpha(128)\n",
    "                    path.fill((255, 0, 0))\n",
    "                    canvas.blit(path, (coord[0] * pix_square_size, (self.grid_size - 1 - coord[1]) * pix_square_size))\n",
    "        \n",
    "        #for i, agent in enumerate(self.agents):\n",
    "            #scoreboard text\n",
    "            #score_text = font.render(f'Agent {i} | {agent.points}', True, \"black\")\n",
    "            #canvas.blit(score_text, (self.window_size + 10 , 10 + (i*50)))\n",
    "            \n",
    "  \n",
    "        for gfl in self.good_food_locs:\n",
    "            good_food_image = pygame.image.load(\"plant.png\").convert_alpha()\n",
    "            good_food_image = pygame.transform.scale(good_food_image, (pix_square_size, pix_square_size))\n",
    "            canvas.blit(good_food_image, (gfl[0] * pix_square_size, (self.grid_size - 1 - gfl[1]) * pix_square_size))\n",
    "\n",
    "        for bfl in self.bad_food_locs:\n",
    "            bad_food_image = pygame.image.load(\"evil_plant.png\").convert_alpha()\n",
    "            bad_food_image = pygame.transform.scale(bad_food_image, (pix_square_size, pix_square_size))\n",
    "            canvas.blit(bad_food_image, (bfl[0] * pix_square_size, (self.grid_size - 1 - bfl[1]) * pix_square_size))\n",
    "\n",
    "        for x in range(self.grid_size + 1):\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                color=0,\n",
    "                start_pos=(0, pix_square_size * x),\n",
    "                end_pos=(self.window_size, pix_square_size * x),\n",
    "                width=1,\n",
    "            )\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                color=0,\n",
    "                start_pos=(pix_square_size * x, 0),\n",
    "                end_pos=(pix_square_size * x, self.window_size),\n",
    "                width=1,\n",
    "            )\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "\n",
    "            self.window.blit(canvas, canvas.get_rect())\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "\n",
    "            #self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        else:\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = foodCollectorEnv(render_mode=\"human\", grid_size=25, game_duration=5000, agents=3, good_food_ratio=0.15,\n",
    "                       bad_food_ratio=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'agent_locs': [[10, 23], [18, 13], [0, 15]],\n",
       "  'good_food_locs': [[21, 14],\n",
       "   [24, 14],\n",
       "   [7, 16],\n",
       "   [6, 10],\n",
       "   [11, 6],\n",
       "   [0, 6],\n",
       "   [18, 6],\n",
       "   [11, 16],\n",
       "   [3, 17],\n",
       "   [6, 23],\n",
       "   [15, 15],\n",
       "   [19, 13],\n",
       "   [1, 3],\n",
       "   [1, 17],\n",
       "   [5, 9],\n",
       "   [14, 15],\n",
       "   [9, 5],\n",
       "   [24, 21],\n",
       "   [6, 21],\n",
       "   [23, 11],\n",
       "   [5, 0],\n",
       "   [15, 6],\n",
       "   [1, 5],\n",
       "   [22, 13],\n",
       "   [22, 1],\n",
       "   [7, 11],\n",
       "   [16, 24],\n",
       "   [0, 16],\n",
       "   [1, 7],\n",
       "   [5, 20],\n",
       "   [8, 1],\n",
       "   [11, 14],\n",
       "   [19, 9],\n",
       "   [23, 6],\n",
       "   [15, 16],\n",
       "   [4, 2],\n",
       "   [4, 11],\n",
       "   [14, 6],\n",
       "   [21, 8],\n",
       "   [6, 5],\n",
       "   [0, 19],\n",
       "   [5, 22],\n",
       "   [17, 18],\n",
       "   [8, 19],\n",
       "   [11, 9],\n",
       "   [19, 7],\n",
       "   [19, 15],\n",
       "   [3, 6],\n",
       "   [15, 24],\n",
       "   [16, 5],\n",
       "   [22, 21],\n",
       "   [4, 18],\n",
       "   [20, 11],\n",
       "   [6, 19],\n",
       "   [5, 24],\n",
       "   [8, 14],\n",
       "   [24, 20],\n",
       "   [0, 23],\n",
       "   [23, 16],\n",
       "   [11, 2],\n",
       "   [8, 21],\n",
       "   [20, 1],\n",
       "   [1, 16],\n",
       "   [10, 24],\n",
       "   [15, 4],\n",
       "   [1, 6],\n",
       "   [13, 24],\n",
       "   [21, 4],\n",
       "   [0, 20],\n",
       "   [22, 9],\n",
       "   [6, 9],\n",
       "   [17, 8],\n",
       "   [2, 20],\n",
       "   [18, 18],\n",
       "   [5, 21],\n",
       "   [1, 19],\n",
       "   [19, 16],\n",
       "   [21, 7],\n",
       "   [20, 24],\n",
       "   [11, 8],\n",
       "   [17, 0],\n",
       "   [6, 3],\n",
       "   [9, 13],\n",
       "   [1, 20],\n",
       "   [24, 7],\n",
       "   [3, 15],\n",
       "   [9, 14],\n",
       "   [3, 12],\n",
       "   [15, 12],\n",
       "   [0, 18],\n",
       "   [23, 22],\n",
       "   [5, 14],\n",
       "   [10, 5],\n",
       "   [22, 7]],\n",
       "  'bad_food_locs': [[2, 22],\n",
       "   [17, 17],\n",
       "   [23, 4],\n",
       "   [17, 13],\n",
       "   [7, 17],\n",
       "   [10, 9],\n",
       "   [13, 11],\n",
       "   [6, 11],\n",
       "   [17, 23],\n",
       "   [1, 11],\n",
       "   [19, 10],\n",
       "   [0, 8],\n",
       "   [13, 5],\n",
       "   [1, 0],\n",
       "   [6, 7],\n",
       "   [17, 15],\n",
       "   [5, 10],\n",
       "   [16, 12],\n",
       "   [15, 0],\n",
       "   [10, 21],\n",
       "   [13, 10],\n",
       "   [23, 20],\n",
       "   [2, 14],\n",
       "   [3, 8],\n",
       "   [11, 10],\n",
       "   [3, 3],\n",
       "   [3, 9],\n",
       "   [8, 24],\n",
       "   [16, 17],\n",
       "   [21, 19],\n",
       "   [6, 14],\n",
       "   [9, 3],\n",
       "   [5, 17],\n",
       "   [2, 0],\n",
       "   [16, 2],\n",
       "   [17, 7],\n",
       "   [13, 19],\n",
       "   [7, 0],\n",
       "   [20, 19],\n",
       "   [4, 7],\n",
       "   [12, 2],\n",
       "   [8, 10],\n",
       "   [11, 18],\n",
       "   [20, 16],\n",
       "   [1, 23],\n",
       "   [8, 3],\n",
       "   [4, 13],\n",
       "   [19, 8],\n",
       "   [21, 0],\n",
       "   [20, 17],\n",
       "   [7, 5],\n",
       "   [4, 9],\n",
       "   [20, 5],\n",
       "   [12, 24],\n",
       "   [18, 16],\n",
       "   [22, 8],\n",
       "   [7, 13],\n",
       "   [22, 17],\n",
       "   [0, 4],\n",
       "   [22, 19],\n",
       "   [17, 11],\n",
       "   [6, 8],\n",
       "   [2, 19],\n",
       "   [20, 3],\n",
       "   [13, 16],\n",
       "   [4, 0],\n",
       "   [12, 4],\n",
       "   [5, 1],\n",
       "   [2, 15],\n",
       "   [9, 23],\n",
       "   [9, 8],\n",
       "   [1, 12],\n",
       "   [19, 5],\n",
       "   [13, 1],\n",
       "   [15, 3],\n",
       "   [15, 9],\n",
       "   [10, 11],\n",
       "   [20, 18],\n",
       "   [22, 10],\n",
       "   [17, 24],\n",
       "   [6, 24],\n",
       "   [19, 3],\n",
       "   [9, 16],\n",
       "   [20, 2],\n",
       "   [7, 7],\n",
       "   [13, 3],\n",
       "   [7, 23],\n",
       "   [10, 8],\n",
       "   [17, 19],\n",
       "   [3, 19],\n",
       "   [12, 14],\n",
       "   [14, 21],\n",
       "   [15, 19],\n",
       "   [14, 1],\n",
       "   [6, 2],\n",
       "   [23, 8],\n",
       "   [16, 10],\n",
       "   [14, 2],\n",
       "   [16, 22],\n",
       "   [17, 1],\n",
       "   [3, 7],\n",
       "   [23, 1],\n",
       "   [22, 3],\n",
       "   [1, 21],\n",
       "   [3, 2],\n",
       "   [18, 4],\n",
       "   [7, 10],\n",
       "   [16, 9],\n",
       "   [17, 16],\n",
       "   [0, 0],\n",
       "   [16, 15],\n",
       "   [21, 13],\n",
       "   [21, 5],\n",
       "   [22, 23],\n",
       "   [3, 0],\n",
       "   [2, 18],\n",
       "   [24, 19],\n",
       "   [14, 5],\n",
       "   [19, 24],\n",
       "   [12, 16],\n",
       "   [7, 18],\n",
       "   [4, 5],\n",
       "   [9, 18],\n",
       "   [15, 7],\n",
       "   [6, 0],\n",
       "   [4, 3],\n",
       "   [11, 19],\n",
       "   [17, 12],\n",
       "   [12, 1],\n",
       "   [24, 13],\n",
       "   [20, 12],\n",
       "   [24, 1],\n",
       "   [14, 24],\n",
       "   [9, 21],\n",
       "   [0, 11],\n",
       "   [15, 17],\n",
       "   [11, 22],\n",
       "   [5, 5],\n",
       "   [9, 6],\n",
       "   [9, 24],\n",
       "   [2, 9],\n",
       "   [18, 21],\n",
       "   [16, 1],\n",
       "   [15, 21],\n",
       "   [13, 18],\n",
       "   [23, 18],\n",
       "   [8, 11],\n",
       "   [13, 12],\n",
       "   [21, 21],\n",
       "   [23, 19],\n",
       "   [24, 10],\n",
       "   [1, 14],\n",
       "   [2, 6],\n",
       "   [16, 4],\n",
       "   [17, 20],\n",
       "   [10, 14],\n",
       "   [17, 6],\n",
       "   [6, 6],\n",
       "   [4, 23],\n",
       "   [6, 4],\n",
       "   [21, 11],\n",
       "   [19, 14],\n",
       "   [18, 14],\n",
       "   [23, 24],\n",
       "   [21, 1],\n",
       "   [12, 11],\n",
       "   [12, 5],\n",
       "   [7, 15],\n",
       "   [13, 14],\n",
       "   [9, 17],\n",
       "   [13, 8],\n",
       "   [24, 23],\n",
       "   [8, 18],\n",
       "   [3, 13],\n",
       "   [1, 15],\n",
       "   [21, 17],\n",
       "   [14, 20],\n",
       "   [24, 2],\n",
       "   [20, 9],\n",
       "   [3, 1],\n",
       "   [2, 10],\n",
       "   [8, 6],\n",
       "   [14, 23],\n",
       "   [13, 6],\n",
       "   [8, 22],\n",
       "   [16, 18],\n",
       "   [13, 4],\n",
       "   [16, 8]]},\n",
       " {'agent_points': [0, 0, 0]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "observation = env._get_obs()\n",
    "while True:\n",
    "    \n",
    "    for i in range(len(env.agents)):\n",
    "        \n",
    "        action = [env.agents[i].run(observation, env.grid_size)]\n",
    "        observation, reward, terminated, info = env.step(action,i)\n",
    "\n",
    "    if terminated:\n",
    "        break\n",
    "pygame.quit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_points': [78, 164, 214]}\n",
      "Agent 2 wins the game with 214 points\n"
     ]
    }
   ],
   "source": [
    "print(info)\n",
    "np.argmax(info['agent_points'])\n",
    "print(f\"Agent {np.argmax(info['agent_points'])} wins the game with {max(info['agent_points'])} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [1,10,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06666666666666667"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst[np.argmin(lst)] / sum(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9333333333333333,\n",
       " 0.33333333333333337,\n",
       " 0.8666666666666667,\n",
       " 0.8666666666666667]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1- lst[i] / sum(lst) for i in range(len(lst))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[312, 99, 593, 580]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[random.choices(lst, weights = [1- lst[i] / sum(lst) for i in range(len(lst))])[0] for _ in range(1000)].count(lst[x]) for x in range(len(lst))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
