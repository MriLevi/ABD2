{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABD2\n",
    "\n",
    "Wij gaan tijdens deze opdracht een food-collector simulatie bouwen.\n",
    "In deze simulatie is het doel van de agents om zo veel mogelijk groen eten op te eten, terwijl ze rood eten vermijden.\n",
    "We gaan deze simulatie grid-based maken. \n",
    "\n",
    "We maken gebruik van de gymnasium API: https://gymnasium.farama.org/\n",
    "\n",
    "Ter visualisatie gebruiken we pygame.\n",
    "\n",
    "\n",
    "### Simulation properties:\n",
    "We beginnen in principe met een grid van 128x128, maar dit kan uitgebreid worden. \n",
    "We zullen de implementatie zoveel mogelijk scalable en aanpasbaar implementeren, door hyperparameters aan te maken voor alle belangrijke properties.\n",
    "\n",
    "- Number of agents\n",
    "- Grid size (default 128x128)\n",
    "- Good food to total square ratio\n",
    "- Good food spawning pattern (maybe)\n",
    "- Bad food to total square ratio\n",
    "- Bad food spawning pattern (maybe)\n",
    "- Episode duration\n",
    "\n",
    "### Agent properties:\n",
    "Actions: up, down, left, right, wait\n",
    "Perception: full information (knows coordinates of other agents, good food, and bad food)\n",
    "Agent rules: not yet specified\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.3.dev8 (SDL 2.0.22, Python 3.10.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pygame\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import random\n",
    "import time\n",
    "import tcod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class agent():\n",
    "    def __init__(self):\n",
    "        self.location = [None, None]\n",
    "        self.points = 0\n",
    "        self.vision_range = 3\n",
    "        self.memory = []\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([0, 0]),\n",
    "            1: np.array([1, 0]),\n",
    "            2: np.array([0, 1]),\n",
    "            3: np.array([-1, 0]),\n",
    "            4: np.array([0, -1])\n",
    "        }\n",
    "        self.path = []\n",
    "\n",
    "    def move(self, direction):\n",
    "        \"\"\"move an agent into a specific direction\"\"\"\n",
    "        \n",
    "        new_location = self.location + direction\n",
    "        self.location = list(new_location)\n",
    "        \n",
    "    def get_quadrant(self,coordinate, grid_size):\n",
    "\n",
    "        if coordinate[0] >= grid_size / 2 and coordinate[1] >= grid_size / 2:\n",
    "            return 1\n",
    "        if coordinate[0] >= grid_size / 2 and coordinate[1] < grid_size / 2:\n",
    "            return 3\n",
    "        if coordinate[0] < grid_size / 2 and coordinate[1] < grid_size / 2:\n",
    "            return 2\n",
    "        if coordinate[0] < grid_size / 2 and coordinate[1] >= grid_size / 2:\n",
    "            return 0\n",
    "    \n",
    "\n",
    "    def clip_vision(self, obs):\n",
    "        \"\"\"clip the observation of the agent to the vision_range\"\"\"\n",
    "\n",
    "        clipped_obs = {}\n",
    "\n",
    "        for k in obs.keys():\n",
    "\n",
    "            clipped_obs[k] = [x for x in obs[k]\n",
    "                      if abs(self.location[0] - x[0]) <= self.vision_range\n",
    "                      and abs(self.location[1] - x[1]) <= self.vision_range\n",
    "                     ]\n",
    "\n",
    "        return clipped_obs\n",
    "    \n",
    "    def get_best_move(self, obs, grid_size):\n",
    "        \"\"\"return the best direction of an agent to take calculated with a*\"\"\"\n",
    "        \n",
    "        cost = np.full((self.vision_range*2 + 1, self.vision_range*2 + 1),2)\n",
    "        \n",
    "        for k in obs.keys():\n",
    "            \n",
    "            new_coords = [[x-self.location[0] + self.vision_range,y-self.location[1]+ self.vision_range]  for x,y in obs[k]]\n",
    "            \n",
    "            if k == 'bad_food_locs':\n",
    "                for x in new_coords:\n",
    "                    cost[x[0]][x[1]] = 10\n",
    "                    # it can be worth it for the agent to cross bad food to get to good food with the current point assignment (-1,5) if it's the only path available\n",
    "            if k == 'good_food_locs':\n",
    "                for x in new_coords:\n",
    "                    cost[x[0]][x[1]] = 1\n",
    "            if k == 'agent_locs':\n",
    "                for x in new_coords:\n",
    "                    cost[x[0]][x[1]] = 0\n",
    "            \n",
    "            # out of bounds squares get value 0\n",
    "            for x in np.argwhere(cost != None):\n",
    "                converted_coord = (np.array(x) - np.array([self.vision_range,self.vision_range]) + self.location)\n",
    "                if converted_coord[0] > grid_size -1 or converted_coord[0] < 0 or converted_coord[1] > grid_size -1 or converted_coord[1] < 0:\n",
    "                    cost[x[0]][x[1]] = 0\n",
    "                    \n",
    "                \n",
    "        good_food_converted_locs = list(zip(*np.where(cost == 1)))\n",
    "        #print(np.rot90(cost, k=1, axes=(0, 1)))\n",
    "    \n",
    "        cost = cost.astype(np.int8) #changed type, now it works\n",
    "        graph = tcod.path.SimpleGraph(cost = cost, cardinal =1, diagonal = 0)\n",
    "        pf = tcod.path.Pathfinder(graph)\n",
    "        pf.add_root((self.vision_range, self.vision_range))\n",
    "        pf.resolve()\n",
    "        \n",
    "           \n",
    "        best_move = None\n",
    "        \n",
    "        # calculate the best paths to all available good_food in vision_range\n",
    "        paths = [pf.path_to(cl)[1:].tolist() for cl in good_food_converted_locs if len(pf.path_to(cl)[1:].tolist()) != 0]\n",
    "\n",
    "        self.path = []\n",
    "        if len(paths) > 0:\n",
    "            shortest_path_index = np.argmin([len(x) for x in paths])\n",
    "            for x in paths[shortest_path_index]:\n",
    "                #undo the earlier conversion:\n",
    "                self.path.append(list(np.array(x) - np.array([-self.location[0] + self.vision_range,-self.location[1]+ self.vision_range])))\n",
    "            best_move = list(np.array(paths[shortest_path_index][0]) - np.array([self.vision_range, self.vision_range]))\n",
    "        \n",
    "        return best_move\n",
    "            \n",
    "    def get_q_dict(self, grid_size):\n",
    "        \"\"\"returns a dictionary with no-good-food in vision range coordinates per quadrant\"\"\"\n",
    "        \n",
    "        q_dict = {\n",
    "            0:[],\n",
    "            1:[],\n",
    "            2:[],\n",
    "            3:[]\n",
    "        }\n",
    "        \n",
    "        empty_coords = []\n",
    "        for x in self.memory:\n",
    "            if len(x['agent_obs']['good_food_locs']) == 0:\n",
    "                if x['agent_location'] not in empty_coords:\n",
    "                    empty_coords.append(x['agent_location'])\n",
    "            \n",
    "        for coord in empty_coords:\n",
    "            q_dict[self.get_quadrant(coord, grid_size)].append(coord)\n",
    "            \n",
    "        return q_dict\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    def pick_action(self,obs, grid_size):\n",
    "        \n",
    "        # clip the observation to the agents vision\n",
    "        obs = self.clip_vision(obs)\n",
    "                \n",
    "        best_move = self.get_best_move(obs, grid_size)\n",
    "\n",
    "        viable_actions = list(self._action_to_direction.keys())\n",
    "\n",
    "        other_agent_locations = [x for x in obs['agent_locs'] if x != self.location]\n",
    "\n",
    "        # Rule 1: agents can't move to a space occupied by another agent\n",
    "        viable_actions = [v for v in viable_actions if list(self.location +  self._action_to_direction[v]) not in other_agent_locations]\n",
    "        # Rule 2: agents can't move out of bounds\n",
    "        viable_actions = [v for v in viable_actions\n",
    "                          if list(self.location +  self._action_to_direction[v])[0] >= 0\n",
    "                          and list(self.location +  self._action_to_direction[v])[1] >= 0\n",
    "                          and list(self.location +  self._action_to_direction[v])[0] < grid_size\n",
    "                          and list(self.location +  self._action_to_direction[v])[1] < grid_size]\n",
    "        \n",
    "\n",
    "        #Rule 3: never step on bad food (while exploring)\n",
    "        viable_actions = [k for k,v in {v:list(self.location + self._action_to_direction[v]) for v in viable_actions}.items()\n",
    "                          if v not in obs['bad_food_locs']]\n",
    "                \n",
    "        action_history = [x['agent_action'] for x in self.memory][-10:]\n",
    "        if len(action_history) >= 10:\n",
    "            if len(list(set(action_history))) == 2:\n",
    "                if len(list(set([action_history[l] for l in range(len(action_history)) if l % 2 == 0]))) == 1 and len(list(set([action_history[l] for l in range(len(action_history)) if l % 2 == 1]))) == 1:\n",
    "                   \n",
    "                    return random.choice(viable_actions)\n",
    "        \n",
    "        #Rule 4: don't go back to zones where the agent has seen no good food\n",
    "        viable_actions_higher_prio = [k for k,v in {v:list(self.location + self._action_to_direction[v]) for v in viable_actions}.items()\n",
    "                          if v not in [x['agent_location'] for x in self.memory if len(x['agent_obs']['good_food_locs'])==0]]\n",
    "         \n",
    "    \n",
    "\n",
    "        if best_move == None:\n",
    "            if len(viable_actions_higher_prio) > 0:\n",
    "                action = random.choice(viable_actions_higher_prio)\n",
    "            else:\n",
    "                action = random.choice(viable_actions)\n",
    "            \n",
    "        else:\n",
    "\n",
    "            action = [x[0] for x in list(self._action_to_direction.items()) if x[1][0] == best_move[0] and x[1][1] == best_move[1]][0]\n",
    "\n",
    "        self.memory.append({'agent_action':action, \"agent_obs\":obs, \"agent_location\":self.location})\n",
    "        self.q_dict = self.get_q_dict(grid_size)\n",
    "        \n",
    "        return action\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class foodCollectorEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", None], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self, render_mode=None, grid_size=128, game_duration=200, agents=1, good_food_ratio=0.1,\n",
    "                 bad_food_ratio=0.1):\n",
    "        self.grid_size = grid_size\n",
    "        self.window_size = 1028\n",
    "        self.game_duration = game_duration * agents\n",
    "        self.current_step = 0\n",
    "        self.agents = [agent() for _ in range(agents)]\n",
    "        self.good_food_ratio = good_food_ratio\n",
    "        self.bad_food_ratio = bad_food_ratio\n",
    "        self.good_food_points = 5\n",
    "        self.bad_food_points = -1\n",
    "        self.render_mode = render_mode\n",
    "        self.window = None\n",
    "        self.grid = np.ones((self.grid_size, self.grid_size))\n",
    "\n",
    "\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'agent_locs': spaces.Sequence(spaces.MultiDiscrete([self.grid_size - 1, self.grid_size - 1])),\n",
    "            'good_food_locs': spaces.Sequence(spaces.MultiDiscrete([self.grid_size - 1, self.grid_size - 1])),\n",
    "            'bad_food_locs': spaces.Sequence(spaces.MultiDiscrete([self.grid_size - 1, self.grid_size - 1])),\n",
    "        })\n",
    "\n",
    "        self.action_space = spaces.Sequence(spaces.Tuple((spaces.MultiDiscrete(len(self.agents)) ,spaces.MultiDiscrete(5) )))\n",
    "\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([0, 0]),\n",
    "            1: np.array([1, 0]),\n",
    "            2: np.array([0, 1]),\n",
    "            3: np.array([-1, 0]),\n",
    "            4: np.array([0, -1])\n",
    "        }\n",
    "\n",
    "        self.good_food_locations = []\n",
    "        self.bad_food_locations = []\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return {\n",
    "            \"agent_locs\": [agent.location for agent in self.agents],\n",
    "            \"good_food_locs\": self.good_food_locs,\n",
    "            \"bad_food_locs\": self.bad_food_locs\n",
    "        }\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        self.agent_locs = []\n",
    "        self.good_food_locs = []\n",
    "        self.bad_food_locs = []\n",
    "\n",
    "\n",
    "        # place agents\n",
    "        while True:\n",
    "            if len(self.agent_locs) >= len(self.agents):\n",
    "                break\n",
    "            loc = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]\n",
    "            if loc not in self.agent_locs:\n",
    "                self.agent_locs.append(loc)\n",
    "\n",
    "\n",
    "        # place good food\n",
    "        while True:\n",
    "            if len(self.good_food_locs) >= round(self.good_food_ratio * self.grid_size * self.grid_size):\n",
    "                break\n",
    "            loc = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]\n",
    "            if loc not in self.agent_locs and loc not in self.good_food_locs and loc not in self.bad_food_locs:\n",
    "                self.good_food_locs.append(loc)\n",
    "\n",
    "        #place bad food\n",
    "        while True:\n",
    "            if len(self.bad_food_locs) >= round(self.bad_food_ratio * self.grid_size * self.grid_size):\n",
    "                break\n",
    "            loc = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]\n",
    "            if loc not in self.agent_locs and loc not in self.good_food_locs and loc not in self.bad_food_locs:\n",
    "                self.bad_food_locs.append(loc)\n",
    "\n",
    "        for i, agent in enumerate(self.agents):\n",
    "            agent.location = self.agent_locs[i]\n",
    "        \n",
    "        observation = self._get_obs()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        info = {\"agent_points\": [agent.points for agent in self.agents]}\n",
    "\n",
    "\n",
    "\n",
    "        return observation, info\n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        direction = self._action_to_direction[action[1]]\n",
    "        \n",
    "        self.agents[action[0]].move(direction)\n",
    "\n",
    "        if self.agents[action[0]].location in self.good_food_locs:\n",
    "            self.good_food_locs.remove(self.agents[action[0]].location)\n",
    "            self.agents[action[0]].points += self.good_food_points\n",
    "\n",
    "        if self.agents[action[0]].location in self.bad_food_locs:\n",
    "            self.bad_food_locs.remove(self.agents[action[0]].location)\n",
    "            self.agents[action[0]].points += self.bad_food_points\n",
    "\n",
    "        terminated = self.current_step >= self.game_duration or (len(self._get_obs()['good_food_locs']) == 0 and self.current_step > 0)\n",
    "        reward = 0 # niet relevant voor nu\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "        info = {\"agent_points\": [agent.points for agent in self.agents]}\n",
    "\n",
    "        self.current_step += 1\n",
    "\n",
    "        return observation, reward, terminated, info\n",
    "\n",
    "    def _is_empty(self, loc):\n",
    "\n",
    "        for agent in self.agents:\n",
    "            if sorted(agent.location) == sorted(loc):\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == \"rgb_array\":\n",
    "            return self._render_frame()\n",
    "\n",
    "    def _render_frame(self):\n",
    "        pygame.font.init()\n",
    "        font = pygame.font.Font(None, 24)\n",
    "        scoreboard_width = 0.2\n",
    "\n",
    "        if self.window is None and self.render_mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.window = pygame.display.set_mode(\n",
    "                (self.window_size + self.window_size * scoreboard_width, self.window_size)\n",
    "            )\n",
    "\n",
    "        canvas = pygame.Surface((self.window_size + self.window_size * scoreboard_width, self.window_size))\n",
    "        canvas.fill((204, 255, 229))\n",
    "        pix_square_size = (\n",
    "                self.window_size / self.grid_size\n",
    "        )\n",
    "\n",
    "        #draw the background for the scoreboard\n",
    "        scoreboard_bg = pygame.Surface((self.window_size*scoreboard_width,self.window_size+self.window_size*scoreboard_width))\n",
    "        scoreboard_bg.fill((255, 255, 255))\n",
    "        scoreboard_bg.set_alpha(255)\n",
    "        canvas.blit(scoreboard_bg, (self.window_size, 0))\n",
    "            \n",
    "        for i, agent in enumerate(self.agents):\n",
    "            #draw agent picture\n",
    "            deer_image = pygame.image.load(\"deer.png\").convert_alpha()\n",
    "            deer_image = pygame.transform.scale(deer_image, (pix_square_size, pix_square_size))\n",
    "            canvas.blit(deer_image, (agent.location[0] * pix_square_size, (self.grid_size - 1 - agent.location[1]) * pix_square_size))\n",
    "\n",
    "            #try to draw vision_range, a bit awkward imo\n",
    "            fov = pygame.Surface((pix_square_size * (agent.vision_range*2+1), pix_square_size * (agent.vision_range*2+1)))\n",
    "            fov.set_alpha(128)\n",
    "            fov.fill((137,137,137))\n",
    "            canvas.blit(fov, ((agent.location[0] * pix_square_size)-pix_square_size*agent.vision_range, ((self.grid_size - 1 - agent.location[1]) * pix_square_size) - pix_square_size * agent.vision_range))\n",
    "\n",
    "            \n",
    "            score_text = font.render(f'Agent {i} | {agent.points}', True, \"black\")\n",
    "            canvas.blit(score_text, (self.window_size + 10 , 10 + (i*50)))\n",
    "            \n",
    "            score_text = font.render(f\"{i}\", True, \"white\")\n",
    "            canvas.blit(score_text, (agent.location[0] * pix_square_size, (self.grid_size - 1 - agent.location[1]) * pix_square_size))\n",
    "            \n",
    "\n",
    "            #path to good food\n",
    "            if len(agent.path) > 1:\n",
    "                for coord in agent.path[1:]:\n",
    "                    #draw the path\n",
    "                    path = pygame.Surface((pix_square_size, pix_square_size))\n",
    "                    path.set_alpha(128)\n",
    "                    path.fill((255, 0, 0))\n",
    "                    canvas.blit(path, (coord[0] * pix_square_size, (self.grid_size - 1 - coord[1]) * pix_square_size))\n",
    "        \n",
    "        #for i, agent in enumerate(self.agents):\n",
    "            #scoreboard text\n",
    "            #score_text = font.render(f'Agent {i} | {agent.points}', True, \"black\")\n",
    "            #canvas.blit(score_text, (self.window_size + 10 , 10 + (i*50)))\n",
    "            \n",
    "  \n",
    "        for gfl in self.good_food_locs:\n",
    "            good_food_image = pygame.image.load(\"plant.png\").convert_alpha()\n",
    "            good_food_image = pygame.transform.scale(good_food_image, (pix_square_size, pix_square_size))\n",
    "            canvas.blit(good_food_image, (gfl[0] * pix_square_size, (self.grid_size - 1 - gfl[1]) * pix_square_size))\n",
    "\n",
    "        for bfl in self.bad_food_locs:\n",
    "            bad_food_image = pygame.image.load(\"evil_plant.png\").convert_alpha()\n",
    "            bad_food_image = pygame.transform.scale(bad_food_image, (pix_square_size, pix_square_size))\n",
    "            canvas.blit(bad_food_image, (bfl[0] * pix_square_size, (self.grid_size - 1 - bfl[1]) * pix_square_size))\n",
    "\n",
    "        for x in range(self.grid_size + 1):\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                color=0,\n",
    "                start_pos=(0, pix_square_size * x),\n",
    "                end_pos=(self.window_size, pix_square_size * x),\n",
    "                width=1,\n",
    "            )\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                color=0,\n",
    "                start_pos=(pix_square_size * x, 0),\n",
    "                end_pos=(pix_square_size * x, self.window_size),\n",
    "                width=1,\n",
    "            )\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "\n",
    "            self.window.blit(canvas, canvas.get_rect())\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "\n",
    "            #self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        else:\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = foodCollectorEnv(render_mode=\"human\", grid_size=25, game_duration=5000, agents=1, good_food_ratio=0.15,\n",
    "                       bad_food_ratio=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'agent_locs': [[16, 5]],\n",
       "  'good_food_locs': [[4, 4],\n",
       "   [19, 24],\n",
       "   [19, 12],\n",
       "   [2, 23],\n",
       "   [22, 19],\n",
       "   [5, 11],\n",
       "   [14, 12],\n",
       "   [4, 12],\n",
       "   [14, 15],\n",
       "   [0, 16],\n",
       "   [4, 23],\n",
       "   [9, 12],\n",
       "   [19, 15],\n",
       "   [3, 12],\n",
       "   [6, 20],\n",
       "   [16, 8],\n",
       "   [9, 13],\n",
       "   [9, 18],\n",
       "   [5, 4],\n",
       "   [19, 8],\n",
       "   [12, 14],\n",
       "   [4, 6],\n",
       "   [17, 12],\n",
       "   [22, 5],\n",
       "   [0, 17],\n",
       "   [15, 20],\n",
       "   [15, 18],\n",
       "   [4, 1],\n",
       "   [24, 12],\n",
       "   [20, 10],\n",
       "   [8, 12],\n",
       "   [6, 11],\n",
       "   [22, 4],\n",
       "   [3, 8],\n",
       "   [9, 7],\n",
       "   [11, 23],\n",
       "   [22, 6],\n",
       "   [2, 18],\n",
       "   [5, 9],\n",
       "   [11, 7],\n",
       "   [1, 4],\n",
       "   [20, 18],\n",
       "   [5, 21],\n",
       "   [11, 17],\n",
       "   [8, 6],\n",
       "   [23, 1],\n",
       "   [22, 7],\n",
       "   [9, 17],\n",
       "   [6, 13],\n",
       "   [24, 16],\n",
       "   [4, 21],\n",
       "   [5, 20],\n",
       "   [21, 2],\n",
       "   [20, 6],\n",
       "   [14, 20],\n",
       "   [18, 11],\n",
       "   [19, 1],\n",
       "   [13, 21],\n",
       "   [0, 5],\n",
       "   [8, 1],\n",
       "   [24, 23],\n",
       "   [5, 16],\n",
       "   [6, 10],\n",
       "   [7, 22],\n",
       "   [6, 12],\n",
       "   [19, 4],\n",
       "   [7, 17],\n",
       "   [24, 6],\n",
       "   [20, 16],\n",
       "   [19, 16],\n",
       "   [11, 8],\n",
       "   [17, 3],\n",
       "   [9, 5],\n",
       "   [13, 6],\n",
       "   [18, 15],\n",
       "   [3, 0],\n",
       "   [21, 16],\n",
       "   [22, 21],\n",
       "   [0, 15],\n",
       "   [13, 17],\n",
       "   [3, 1],\n",
       "   [5, 15],\n",
       "   [22, 10],\n",
       "   [12, 2],\n",
       "   [5, 5],\n",
       "   [18, 6],\n",
       "   [0, 20],\n",
       "   [15, 1],\n",
       "   [8, 9],\n",
       "   [8, 5],\n",
       "   [3, 2],\n",
       "   [22, 20],\n",
       "   [2, 20],\n",
       "   [21, 9]],\n",
       "  'bad_food_locs': [[10, 7],\n",
       "   [13, 18],\n",
       "   [10, 18],\n",
       "   [18, 5],\n",
       "   [0, 11],\n",
       "   [19, 22],\n",
       "   [15, 19],\n",
       "   [22, 22],\n",
       "   [14, 19],\n",
       "   [6, 22],\n",
       "   [16, 7],\n",
       "   [15, 8],\n",
       "   [20, 4],\n",
       "   [2, 22],\n",
       "   [9, 22],\n",
       "   [23, 5],\n",
       "   [13, 13],\n",
       "   [6, 24],\n",
       "   [22, 9],\n",
       "   [5, 1],\n",
       "   [12, 5],\n",
       "   [18, 17],\n",
       "   [14, 3],\n",
       "   [9, 23],\n",
       "   [8, 23],\n",
       "   [4, 0],\n",
       "   [4, 11],\n",
       "   [12, 24],\n",
       "   [12, 18],\n",
       "   [18, 4],\n",
       "   [17, 0],\n",
       "   [1, 0],\n",
       "   [23, 16],\n",
       "   [23, 13],\n",
       "   [13, 24],\n",
       "   [10, 11],\n",
       "   [2, 21],\n",
       "   [11, 0],\n",
       "   [20, 20],\n",
       "   [13, 4],\n",
       "   [4, 19],\n",
       "   [12, 0],\n",
       "   [8, 13],\n",
       "   [1, 7],\n",
       "   [11, 20],\n",
       "   [14, 4],\n",
       "   [3, 9],\n",
       "   [24, 18],\n",
       "   [13, 20],\n",
       "   [3, 14],\n",
       "   [7, 6],\n",
       "   [2, 19],\n",
       "   [2, 8],\n",
       "   [3, 15],\n",
       "   [16, 4],\n",
       "   [22, 1],\n",
       "   [4, 15],\n",
       "   [22, 15],\n",
       "   [10, 10],\n",
       "   [23, 22],\n",
       "   [12, 1],\n",
       "   [13, 14],\n",
       "   [5, 13],\n",
       "   [2, 7],\n",
       "   [21, 4],\n",
       "   [9, 0],\n",
       "   [19, 17],\n",
       "   [10, 4],\n",
       "   [7, 4],\n",
       "   [16, 21],\n",
       "   [4, 18],\n",
       "   [20, 1],\n",
       "   [10, 19],\n",
       "   [15, 3],\n",
       "   [10, 14],\n",
       "   [5, 17],\n",
       "   [20, 14],\n",
       "   [10, 20],\n",
       "   [0, 23],\n",
       "   [24, 11],\n",
       "   [4, 9],\n",
       "   [6, 15],\n",
       "   [16, 20],\n",
       "   [10, 2],\n",
       "   [23, 3],\n",
       "   [10, 0],\n",
       "   [10, 22],\n",
       "   [16, 13],\n",
       "   [17, 20],\n",
       "   [7, 9],\n",
       "   [12, 17],\n",
       "   [2, 10],\n",
       "   [3, 4],\n",
       "   [14, 8],\n",
       "   [1, 5],\n",
       "   [10, 21],\n",
       "   [8, 16],\n",
       "   [12, 16],\n",
       "   [5, 0],\n",
       "   [0, 0],\n",
       "   [24, 7],\n",
       "   [20, 7],\n",
       "   [12, 4],\n",
       "   [7, 3],\n",
       "   [0, 22],\n",
       "   [15, 5],\n",
       "   [13, 5],\n",
       "   [8, 10],\n",
       "   [15, 13],\n",
       "   [10, 5],\n",
       "   [14, 5],\n",
       "   [24, 8],\n",
       "   [0, 8],\n",
       "   [15, 17],\n",
       "   [17, 13],\n",
       "   [20, 11],\n",
       "   [12, 12],\n",
       "   [16, 11],\n",
       "   [7, 23],\n",
       "   [6, 14],\n",
       "   [22, 0],\n",
       "   [2, 16],\n",
       "   [5, 8],\n",
       "   [17, 9],\n",
       "   [1, 18],\n",
       "   [6, 6],\n",
       "   [24, 14],\n",
       "   [8, 2],\n",
       "   [15, 9],\n",
       "   [17, 14],\n",
       "   [23, 14],\n",
       "   [22, 13],\n",
       "   [20, 13],\n",
       "   [3, 6],\n",
       "   [17, 6],\n",
       "   [18, 3],\n",
       "   [21, 19],\n",
       "   [20, 2],\n",
       "   [5, 24],\n",
       "   [19, 20],\n",
       "   [23, 20],\n",
       "   [17, 11],\n",
       "   [0, 1],\n",
       "   [21, 1],\n",
       "   [20, 23],\n",
       "   [2, 11],\n",
       "   [10, 24],\n",
       "   [11, 19],\n",
       "   [3, 5],\n",
       "   [0, 6],\n",
       "   [12, 19],\n",
       "   [9, 15],\n",
       "   [9, 6],\n",
       "   [10, 13],\n",
       "   [12, 15],\n",
       "   [0, 13],\n",
       "   [4, 17],\n",
       "   [9, 2],\n",
       "   [15, 15],\n",
       "   [11, 16],\n",
       "   [0, 4],\n",
       "   [15, 6],\n",
       "   [20, 0],\n",
       "   [17, 22],\n",
       "   [3, 10],\n",
       "   [3, 11],\n",
       "   [1, 15],\n",
       "   [0, 18],\n",
       "   [17, 24],\n",
       "   [10, 17],\n",
       "   [7, 11],\n",
       "   [0, 12],\n",
       "   [16, 12],\n",
       "   [11, 2],\n",
       "   [11, 5],\n",
       "   [15, 10],\n",
       "   [8, 4],\n",
       "   [8, 17],\n",
       "   [9, 24],\n",
       "   [6, 23],\n",
       "   [21, 14],\n",
       "   [3, 16],\n",
       "   [7, 14],\n",
       "   [7, 18],\n",
       "   [24, 24],\n",
       "   [17, 19],\n",
       "   [7, 20],\n",
       "   [20, 21]]},\n",
       " {'agent_points': [0]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "observation = env._get_obs()\n",
    "while True:\n",
    "    \n",
    "    for i in range(len(env.agents)):\n",
    "        \n",
    "        action = [i,env.agents[i].pick_action(observation, env.grid_size)]\n",
    "        observation, reward, terminated, info = env.step(action)\n",
    "\n",
    "    if terminated:\n",
    "        break\n",
    "pygame.quit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_points': [457]}\n",
      "Agent 0 wins the game with 457 points\n"
     ]
    }
   ],
   "source": [
    "print(info)\n",
    "np.argmax(info['agent_points'])\n",
    "print(f\"Agent {np.argmax(info['agent_points'])} wins the game with {max(info['agent_points'])} points\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
