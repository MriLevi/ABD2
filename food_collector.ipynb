{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ABD2\n",
    "\n",
    "Wij gaan tijdens deze opdracht een food-collector simulatie bouwen.\n",
    "In deze simulatie is het doel van de agents om zo veel mogelijk groen eten op te eten, terwijl ze rood eten vermijden.\n",
    "We gaan deze simulatie grid-based maken. \n",
    "\n",
    "We maken gebruik van de gymnasium API: https://gymnasium.farama.org/\n",
    "\n",
    "Ter visualisatie gebruiken we pygame.\n",
    "\n",
    "\n",
    "### Simulation properties:\n",
    "We beginnen in principe met een grid van 128x128, maar dit kan uitgebreid worden. \n",
    "We zullen de implementatie zoveel mogelijk scalable en aanpasbaar implementeren, door hyperparameters aan te maken voor alle belangrijke properties.\n",
    "\n",
    "- Number of agents\n",
    "- Grid size (default 128x128)\n",
    "- Good food to total square ratio\n",
    "- Good food spawning pattern (maybe)\n",
    "- Bad food to total square ratio\n",
    "- Bad food spawning pattern (maybe)\n",
    "- Episode duration\n",
    "\n",
    "### Agent properties:\n",
    "Actions: up, down, left, right, wait\n",
    "Perception: full information (knows coordinates of other agents, good food, and bad food)\n",
    "Agent rules: not yet specified\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.3 (SDL 2.0.22, Python 3.9.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pygame\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import random\n",
    "import time\n",
    "import tcod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class agent():\n",
    "    def __init__(self):\n",
    "        self.location = [None, None]\n",
    "        self.points = 0\n",
    "        self.vision_range = 3\n",
    "        self.memory = []\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([0, 0]),\n",
    "            1: np.array([1, 0]),\n",
    "            2: np.array([0, 1]),\n",
    "            3: np.array([-1, 0]),\n",
    "            4: np.array([0, -1])\n",
    "        }\n",
    "\n",
    "    def move(self, direction, grid_size):\n",
    "        new_location = self.location + direction\n",
    "        self.location = list(new_location)\n",
    "\n",
    "    def clip_vision(self, obs):\n",
    "\n",
    "        clipped_obs = {}\n",
    "\n",
    "        for k in obs.keys():\n",
    "\n",
    "            clipped_obs[k] = [x for x in obs[k]\n",
    "                      if abs(self.location[0] - x[0]) <= self.vision_range\n",
    "                      and abs(self.location[1] - x[1]) <= self.vision_range\n",
    "                     ]\n",
    "\n",
    "        return clipped_obs\n",
    "\n",
    "    def pick_action(self,obs, grid_size):\n",
    "        \n",
    "        ##TEMPORARY GARBAGE\n",
    "        grid = np.ndarray((grid_size, grid_size))\n",
    "\n",
    "        # clip the observation to the agents vision\n",
    "        obs = self.clip_vision(obs)\n",
    "        good_food_converted_locs = []\n",
    "        \n",
    "        cost = np.ones((self.vision_range*2 + 1, self.vision_range*2 + 1))\n",
    "        for k in obs.keys():\n",
    "            for x in obs[k]:\n",
    "                converted_coordinate = [x[0]-self.location[0] + self.vision_range, x[1]-self.location[1] + self.vision_range]\n",
    "                \n",
    "                if k == 'agent_locs' or k == 'bad_food_locs':\n",
    "                    cost[converted_coordinate[0]][converted_coordinate[1]] = 9999\n",
    "                if k == 'good_food_locs':\n",
    "                    cost[converted_coordinate[0]][converted_coordinate[1]] = -1\n",
    "                    good_food_converted_locs.append(converted_coordinate)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "        cost = cost.astype(np.int64)\n",
    "        \n",
    "        #print(cost)\n",
    "                    \n",
    "\n",
    "        graph = tcod.path.SimpleGraph(cost = cost, cardinal =1, diagonal = 0)\n",
    "        CARDINAL =[[0,1,0],[1,0,1],[0,1,0]]\n",
    "        pf = tcod.path.Pathfinder(graph)\n",
    "        pf.add_root((self.vision_range, self.vision_range))\n",
    "        pf.resolve()\n",
    "   \n",
    "        for cl in good_food_converted_locs:\n",
    "            print(pf.path_to(cl))\n",
    "            #print()\n",
    "            pass\n",
    "            \n",
    "        ##END TEMPORARY GARBAGE\n",
    "            pass\n",
    "        viable_actions = list(self._action_to_direction.keys())\n",
    "\n",
    "        other_agent_locations = [x for x in obs['agent_locs'] if x != self.location]\n",
    "\n",
    "        # Rule 1: agents can't move to a space occupied by another agent\n",
    "        viable_actions = [v for v in viable_actions if list(self.location +  self._action_to_direction[v]) not in other_agent_locations]\n",
    "        # Rule 2: agents can't move out of bounds\n",
    "        viable_actions = [v for v in viable_actions\n",
    "                          if list(self.location +  self._action_to_direction[v])[0] >= 0\n",
    "                          and list(self.location +  self._action_to_direction[v])[1] >= 0\n",
    "                          and list(self.location +  self._action_to_direction[v])[0] < grid_size\n",
    "                          and list(self.location +  self._action_to_direction[v])[1] < grid_size]\n",
    "\n",
    "        action = random.choice(viable_actions)\n",
    "        self.memory.append({'agent_action':action, \"agent_obs\":obs, \"agent_location\":self.location})\n",
    "        return action\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class foodCollectorEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", None], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self, render_mode=None, grid_size=128, game_duration=200, agents=1, good_food_ratio=0.1,\n",
    "                 bad_food_ratio=0.1):\n",
    "        self.grid_size = grid_size\n",
    "        self.window_size = 720\n",
    "        self.game_duration = game_duration * agents\n",
    "        self.current_step = 0\n",
    "        self.agents = [agent() for _ in range(agents)]\n",
    "        self.good_food_ratio = good_food_ratio\n",
    "        self.bad_food_ratio = bad_food_ratio\n",
    "        self.good_food_points = 5\n",
    "        self.bad_food_points = -1\n",
    "        self.render_mode = render_mode\n",
    "        self.window = None\n",
    "        self.grid = np.ones((self.grid_size, self.grid_size))\n",
    "\n",
    "\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'agent_locs': spaces.Sequence(spaces.MultiDiscrete([self.grid_size - 1, self.grid_size - 1])),\n",
    "            'good_food_locs': spaces.Sequence(spaces.MultiDiscrete([self.grid_size - 1, self.grid_size - 1])),\n",
    "            'bad_food_locs': spaces.Sequence(spaces.MultiDiscrete([self.grid_size - 1, self.grid_size - 1])),\n",
    "        })\n",
    "\n",
    "        self.action_space = spaces.Sequence(spaces.Tuple((spaces.MultiDiscrete(len(self.agents)) ,spaces.MultiDiscrete(5) )))\n",
    "\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([0, 0]),\n",
    "            1: np.array([1, 0]),\n",
    "            2: np.array([0, 1]),\n",
    "            3: np.array([-1, 0]),\n",
    "            4: np.array([0, -1])\n",
    "        }\n",
    "\n",
    "        self.good_food_locations = []\n",
    "        self.bad_food_locations = []\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return {\n",
    "            \"agent_locs\": [agent.location for agent in self.agents],\n",
    "            \"good_food_locs\": self.good_food_locs,\n",
    "            \"bad_food_locs\": self.bad_food_locs\n",
    "        }\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        self.agent_locs = []\n",
    "        self.good_food_locs = []\n",
    "        self.bad_food_locs = []\n",
    "\n",
    "\n",
    "        # place agents\n",
    "        while True:\n",
    "            if len(self.agent_locs) >= len(self.agents):\n",
    "                break\n",
    "            loc = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]\n",
    "            if loc not in self.agent_locs:\n",
    "                self.agent_locs.append(loc)\n",
    "\n",
    "\n",
    "        # place good food\n",
    "        while True:\n",
    "            if len(self.good_food_locs) >= round(self.good_food_ratio * self.grid_size * self.grid_size):\n",
    "                break\n",
    "            loc = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]\n",
    "            if loc not in self.agent_locs and loc not in self.good_food_locs and loc not in self.bad_food_locs:\n",
    "                self.good_food_locs.append(loc)\n",
    "\n",
    "        #place bad food\n",
    "        while True:\n",
    "            if len(self.bad_food_locs) >= round(self.bad_food_ratio * self.grid_size * self.grid_size):\n",
    "                break\n",
    "            loc = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]\n",
    "            if loc not in self.agent_locs and loc not in self.good_food_locs and loc not in self.bad_food_locs:\n",
    "                self.bad_food_locs.append(loc)\n",
    "\n",
    "        for i, agent in enumerate(self.agents):\n",
    "            agent.location = self.agent_locs[i]\n",
    "        \n",
    "        observation = self._get_obs()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        info = {\"agent_points\": [agent.points for agent in self.agents]}\n",
    "\n",
    "\n",
    "\n",
    "        return observation, info\n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        #populate the grid for pathfinding\n",
    "        for i in self.good_food_locs:\n",
    "            self.grid[i[0], i[1]] = 1\n",
    "        for i in self.bad_food_locs:\n",
    "            self.grid[i[0], i[1]] = 9999\n",
    "        for i in self.agent_locs:\n",
    "            self.grid[i[0], i[1]] = 9999\n",
    "\n",
    "        direction = self._action_to_direction[action[1]]\n",
    "        \n",
    "        self.agents[action[0]].move(direction, self.grid_size)\n",
    "\n",
    "        if self.agents[action[0]].location in self.good_food_locs:\n",
    "            self.good_food_locs.remove(self.agents[action[0]].location)\n",
    "            self.agents[action[0]].points += self.good_food_points\n",
    "\n",
    "        if self.agents[action[0]].location in self.bad_food_locs:\n",
    "            self.bad_food_locs.remove(self.agents[action[0]].location)\n",
    "            self.agents[action[0]].points += self.bad_food_points\n",
    "\n",
    "        terminated = self.current_step >= self.game_duration or (len(self._get_obs()['good_food_locs']) == 0 and self.current_step > 0)\n",
    "        reward = 0 # niet relevant voor nu\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "        info = {\"agent_points\": [agent.points for agent in self.agents]}\n",
    "\n",
    "        self.current_step += 1\n",
    "        time.sleep(0)\n",
    "\n",
    "        return observation, reward, terminated, info\n",
    "\n",
    "    def _is_empty(self, loc):\n",
    "\n",
    "        for agent in self.agents:\n",
    "            if sorted(agent.location) == sorted(loc):\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == \"rgb_array\":\n",
    "            return self._render_frame()\n",
    "\n",
    "    def _render_frame(self):\n",
    "        pygame.font.init()\n",
    "        font = pygame.font.Font(None, 24)\n",
    "        scoreboard_width = 0.2\n",
    "\n",
    "        if self.window is None and self.render_mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.window = pygame.display.set_mode(\n",
    "                (self.window_size + self.window_size * scoreboard_width, self.window_size)\n",
    "            )\n",
    "\n",
    "        canvas = pygame.Surface((self.window_size + self.window_size * scoreboard_width, self.window_size))\n",
    "        canvas.fill((204, 255, 229))\n",
    "        pix_square_size = (\n",
    "                self.window_size / self.grid_size\n",
    "        )\n",
    "\n",
    "\n",
    "        for i, agent in enumerate(self.agents):\n",
    "            deer_image = pygame.image.load(\"deer.png\").convert_alpha()\n",
    "            deer_image = pygame.transform.scale(deer_image, (pix_square_size, pix_square_size))\n",
    "            canvas.blit(deer_image, (agent.location[0] * pix_square_size, (self.grid_size - 1 - agent.location[1]) * pix_square_size))\n",
    "\n",
    "            #try to draw vision_range, a bit awkward imo\n",
    "            fov = pygame.Surface((pix_square_size * (agent.vision_range*2+1), pix_square_size * (agent.vision_range*2+1)))\n",
    "            fov.set_alpha(128)\n",
    "            fov.fill((137,137,137))\n",
    "            canvas.blit(fov, ((agent.location[0] * pix_square_size)-pix_square_size*agent.vision_range, ((self.grid_size - 1 - agent.location[1]) * pix_square_size) - pix_square_size * agent.vision_range))\n",
    "\n",
    "            scoreboard_bg = pygame.Surface((self.window_size*scoreboard_width,self.window_size+self.window_size*scoreboard_width))\n",
    "            scoreboard_bg.fill((255, 255, 255))\n",
    "            scoreboard_bg.set_alpha(255)\n",
    "\n",
    "            canvas.blit(scoreboard_bg, (self.window_size, 0))\n",
    "            score_text = font.render(f\"{i}\", True, \"white\")\n",
    "            canvas.blit(score_text, (agent.location[0] * pix_square_size, (self.grid_size - 1 - agent.location[1]) * pix_square_size))\n",
    "\n",
    "\n",
    "\n",
    "        for gfl in self.good_food_locs:\n",
    "            good_food_image = pygame.image.load(\"plant.png\").convert_alpha()\n",
    "            good_food_image = pygame.transform.scale(good_food_image, (pix_square_size, pix_square_size))\n",
    "            canvas.blit(good_food_image, (gfl[0] * pix_square_size, (self.grid_size - 1 - gfl[1]) * pix_square_size))\n",
    "\n",
    "        for bfl in self.bad_food_locs:\n",
    "            bad_food_image = pygame.image.load(\"evil_plant.png\").convert_alpha()\n",
    "            bad_food_image = pygame.transform.scale(bad_food_image, (pix_square_size, pix_square_size))\n",
    "            canvas.blit(bad_food_image, (bfl[0] * pix_square_size, (self.grid_size - 1 - bfl[1]) * pix_square_size))\n",
    "\n",
    "        for x in range(self.grid_size + 1):\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                color=0,\n",
    "                start_pos=(0, pix_square_size * x),\n",
    "                end_pos=(self.window_size, pix_square_size * x),\n",
    "                width=1,\n",
    "            )\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                color=0,\n",
    "                start_pos=(pix_square_size * x, 0),\n",
    "                end_pos=(pix_square_size * x, self.window_size),\n",
    "                width=1,\n",
    "            )\n",
    "\n",
    "        for i, agent in enumerate(self.agents):\n",
    "\n",
    "            score_text = font.render(f'Agent {i} | {agent.points}', True, \"black\")\n",
    "            canvas.blit(score_text, (self.window_size + 10 , 10 + (i*50)))\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "\n",
    "            self.window.blit(canvas, canvas.get_rect())\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "\n",
    "            #self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        else:\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
    "            )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = foodCollectorEnv(render_mode=\"human\", grid_size=16, game_duration=50, agents=10, good_food_ratio=0.1,\n",
    "                       bad_food_ratio=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'agent_locs': [[11, 12],\n",
       "   [10, 4],\n",
       "   [3, 4],\n",
       "   [3, 6],\n",
       "   [3, 9],\n",
       "   [8, 6],\n",
       "   [15, 0],\n",
       "   [15, 6],\n",
       "   [5, 6],\n",
       "   [11, 0]],\n",
       "  'good_food_locs': [[2, 0],\n",
       "   [15, 5],\n",
       "   [5, 7],\n",
       "   [12, 11],\n",
       "   [0, 11],\n",
       "   [1, 15],\n",
       "   [6, 7],\n",
       "   [8, 11],\n",
       "   [0, 4],\n",
       "   [13, 7],\n",
       "   [15, 7],\n",
       "   [9, 8],\n",
       "   [2, 1],\n",
       "   [10, 9],\n",
       "   [0, 3],\n",
       "   [7, 8],\n",
       "   [13, 8],\n",
       "   [7, 7],\n",
       "   [10, 12],\n",
       "   [4, 2],\n",
       "   [3, 1],\n",
       "   [0, 13],\n",
       "   [1, 7],\n",
       "   [15, 8],\n",
       "   [9, 7],\n",
       "   [2, 6]],\n",
       "  'bad_food_locs': [[12, 14],\n",
       "   [9, 11],\n",
       "   [14, 13],\n",
       "   [12, 3],\n",
       "   [12, 9],\n",
       "   [1, 5],\n",
       "   [7, 10],\n",
       "   [15, 13],\n",
       "   [6, 10],\n",
       "   [3, 8],\n",
       "   [4, 10],\n",
       "   [4, 7],\n",
       "   [1, 12],\n",
       "   [7, 3],\n",
       "   [8, 14],\n",
       "   [8, 2],\n",
       "   [14, 8],\n",
       "   [7, 2],\n",
       "   [0, 6],\n",
       "   [15, 12],\n",
       "   [12, 1],\n",
       "   [5, 9],\n",
       "   [2, 12],\n",
       "   [4, 14],\n",
       "   [1, 9],\n",
       "   [13, 1],\n",
       "   [4, 12],\n",
       "   [7, 9],\n",
       "   [1, 4],\n",
       "   [2, 11],\n",
       "   [12, 7],\n",
       "   [5, 10],\n",
       "   [9, 5],\n",
       "   [9, 13],\n",
       "   [11, 14],\n",
       "   [9, 6],\n",
       "   [0, 5],\n",
       "   [8, 13],\n",
       "   [12, 2],\n",
       "   [10, 14],\n",
       "   [7, 4],\n",
       "   [12, 5],\n",
       "   [1, 11],\n",
       "   [9, 2],\n",
       "   [15, 10],\n",
       "   [6, 6],\n",
       "   [8, 4],\n",
       "   [15, 4],\n",
       "   [14, 12],\n",
       "   [8, 9],\n",
       "   [7, 15]]},\n",
       " {'agent_points': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 2]]\n",
      "[[0 2]]\n",
      "[[2 0]]\n",
      "[[2 3]]\n",
      "[[6 6]]\n",
      "[[0 6]]\n",
      "[[2 6]]\n",
      "[[5 6]]\n",
      "[[6 6]]\n",
      "[[0 3]]\n",
      "[[2 0]]\n",
      "[[0 2]]\n",
      "[[4 1]]\n",
      "[[3 0]]\n",
      "[[1 6]]\n",
      "[[2 5]]\n",
      "[[5 4]]\n",
      "[[6 4]]\n",
      "[[0 1]]\n",
      "[[0 0]]\n",
      "[[1 4]]\n",
      "[[2 3]]\n",
      "[[5 1]]\n",
      "[[0 5]]\n",
      "[[6 1]]\n",
      "[[1 1]]\n",
      "[[0 4]]\n",
      "[[1 4]]\n",
      "[[4 5]]\n",
      "[[5 6]]\n",
      "[[2 5]]\n",
      "[[2 4]]\n",
      "[[4 4]]\n",
      "[[3 2]]\n",
      "[[1 4]]\n",
      "[[3 4]]\n",
      "[[1 5]]\n",
      "[[3 5]]\n",
      "[[3 4]]\n",
      "[[4 4]]\n",
      "[[5 5]]\n",
      "[[5 4]]\n",
      "[[4 2]]\n",
      "[[0 2]]\n",
      "[[2 0]]\n",
      "[[2 3]]\n",
      "[[6 5]]\n",
      "[[2 6]]\n",
      "[[0 6]]\n",
      "[[6 6]]\n",
      "[[0 5]]\n",
      "[[2 5]]\n",
      "[[5 6]]\n",
      "[[1 0]]\n",
      "[[6 6]]\n",
      "[[3 1]]\n",
      "[[2 0]]\n",
      "[[0 6]]\n",
      "[[1 1]]\n",
      "[[1 0]]\n",
      "[[2 4]]\n",
      "[[1 5]]\n",
      "[[2 1]]\n",
      "[[1 3]]\n",
      "[[4 4]]\n",
      "[[5 5]]\n",
      "[[2 4]]\n",
      "[[2 3]]\n",
      "[[4 3]]\n",
      "[[3 1]]\n",
      "[[1 3]]\n",
      "[[1 4]]\n",
      "[[3 4]]\n",
      "[[4 3]]\n",
      "[[5 4]]\n",
      "[[5 3]]\n",
      "[[3 2]]\n",
      "[[1 0]]\n",
      "[[1 3]]\n",
      "[[6 5]]\n",
      "[[2 6]]\n",
      "[[0 6]]\n",
      "[[6 6]]\n",
      "[[0 5]]\n",
      "[[6 6]]\n",
      "[[0 3]]\n",
      "[[2 0]]\n",
      "[[0 2]]\n",
      "[[4 1]]\n",
      "[[3 0]]\n",
      "[[1 6]]\n",
      "[[2 1]]\n",
      "[[2 0]]\n",
      "[[3 4]]\n",
      "[[1 6]]\n",
      "[[2 2]]\n",
      "[[0 3]]\n",
      "[[3 4]]\n",
      "[[4 5]]\n",
      "[[1 4]]\n",
      "[[1 3]]\n",
      "[[4 1]]\n",
      "[[2 3]]\n",
      "[[2 4]]\n",
      "[[4 4]]\n",
      "[[4 4]]\n",
      "[[5 5]]\n",
      "[[5 4]]\n",
      "[[3 2]]\n",
      "[[1 0]]\n",
      "[[1 3]]\n",
      "[[6 6]]\n",
      "[[0 6]]\n",
      "[[5 6]]\n",
      "[[1 0]]\n",
      "[[6 6]]\n",
      "[[3 1]]\n",
      "[[2 0]]\n",
      "[[0 6]]\n",
      "[[1 1]]\n",
      "[[1 0]]\n",
      "[[2 4]]\n",
      "[[1 6]]\n",
      "[[2 2]]\n",
      "[[6 3]]\n",
      "[[2 4]]\n",
      "[[3 5]]\n",
      "[[0 4]]\n",
      "[[6 4]]\n",
      "[[0 3]]\n",
      "[[4 2]]\n",
      "[[2 4]]\n",
      "[[2 5]]\n",
      "[[4 5]]\n",
      "[[4 4]]\n",
      "[[5 5]]\n",
      "[[5 4]]\n",
      "[[4 2]]\n",
      "[[0 2]]\n",
      "[[2 0]]\n",
      "[[2 3]]\n",
      "[[0 6]]\n",
      "[[1 6]]\n",
      "[[5 6]]\n",
      "[[1 0]]\n",
      "[[6 6]]\n",
      "[[3 1]]\n",
      "[[2 0]]\n",
      "[[0 6]]\n",
      "[[6 4]]\n",
      "[[0 1]]\n",
      "[[0 0]]\n",
      "[[1 4]]\n",
      "[[1 5]]\n",
      "[[2 1]]\n",
      "[[6 3]]\n",
      "[[2 4]]\n",
      "[[3 5]]\n",
      "[[0 4]]\n",
      "[[6 4]]\n",
      "[[0 3]]\n",
      "[[4 3]]\n",
      "[[2 5]]\n",
      "[[2 6]]\n",
      "[[4 6]]\n",
      "[[4 4]]\n",
      "[[5 5]]\n",
      "[[5 4]]\n",
      "[[4 2]]\n",
      "[[0 2]]\n",
      "[[2 0]]\n",
      "[[2 3]]\n",
      "[[0 6]]\n",
      "[[1 6]]\n",
      "[[6 6]]\n",
      "[[0 3]]\n",
      "[[2 0]]\n",
      "[[0 2]]\n",
      "[[4 1]]\n",
      "[[3 0]]\n",
      "[[1 6]]\n",
      "[[6 4]]\n",
      "[[0 1]]\n",
      "[[0 0]]\n",
      "[[1 4]]\n",
      "[[2 5]]\n",
      "[[3 1]]\n",
      "[[6 4]]\n",
      "[[2 5]]\n",
      "[[3 6]]\n",
      "[[0 5]]\n",
      "[[6 5]]\n",
      "[[0 4]]\n",
      "[[1 5]]\n",
      "[[1 6]]\n",
      "[[3 6]]\n",
      "[[4 4]]\n",
      "[[5 5]]\n",
      "[[5 4]]\n",
      "[[4 1]]\n",
      "[[0 1]]\n",
      "[[2 2]]\n",
      "[[0 6]]\n",
      "[[1 6]]\n",
      "[[1 3]]\n",
      "[[3 0]]\n",
      "[[1 2]]\n",
      "[[5 1]]\n",
      "[[4 0]]\n",
      "[[2 6]]\n",
      "[[6 3]]\n",
      "[[0 0]]\n",
      "[[1 3]]\n",
      "[[2 4]]\n",
      "[[2 6]]\n",
      "[[3 0]]\n",
      "[[0 4]]\n",
      "[[3 5]]\n",
      "[[4 6]]\n",
      "[[1 5]]\n",
      "[[1 4]]\n",
      "[[1 5]]\n",
      "[[1 6]]\n",
      "[[3 6]]\n",
      "[[4 4]]\n",
      "[[5 5]]\n",
      "[[5 4]]\n",
      "[[4 1]]\n",
      "[[0 1]]\n",
      "[[2 2]]\n",
      "[[1 6]]\n",
      "[[2 6]]\n",
      "[[6 6]]\n",
      "[[0 3]]\n",
      "[[2 0]]\n",
      "[[0 2]]\n",
      "[[4 1]]\n",
      "[[3 0]]\n",
      "[[1 6]]\n",
      "[[6 4]]\n",
      "[[0 1]]\n",
      "[[0 0]]\n",
      "[[1 4]]\n",
      "[[3 4]]\n",
      "[[3 6]]\n",
      "[[4 0]]\n",
      "[[0 3]]\n",
      "[[3 4]]\n",
      "[[4 5]]\n",
      "[[1 4]]\n",
      "[[1 3]]\n",
      "[[1 5]]\n",
      "[[1 6]]\n",
      "[[3 6]]\n",
      "[[4 5]]\n",
      "[[5 6]]\n",
      "[[5 5]]\n",
      "[[2 0]]\n",
      "[[4 0]]\n",
      "[[0 0]]\n",
      "[[2 1]]\n",
      "[[1 5]]\n",
      "[[4 6]]\n",
      "[[2 6]]\n",
      "[[2 5]]\n",
      "[[1 3]]\n",
      "[[3 0]]\n",
      "[[1 2]]\n",
      "[[5 1]]\n",
      "[[4 0]]\n",
      "[[2 6]]\n",
      "[[6 3]]\n",
      "[[0 0]]\n",
      "[[1 3]]\n",
      "[[3 4]]\n",
      "[[3 6]]\n",
      "[[4 0]]\n",
      "[[0 4]]\n",
      "[[3 5]]\n",
      "[[4 6]]\n",
      "[[1 5]]\n",
      "[[1 4]]\n",
      "[[1 6]]\n",
      "[[5 5]]\n",
      "[[6 6]]\n",
      "[[6 5]]\n",
      "[[3 0]]\n",
      "[[0 5]]\n",
      "[[4 1]]\n",
      "[[0 1]]\n",
      "[[2 2]]\n",
      "[[1 4]]\n",
      "[[4 5]]\n",
      "[[5 6]]\n",
      "[[2 5]]\n",
      "[[2 4]]\n",
      "[[2 3]]\n",
      "[[4 0]]\n",
      "[[2 2]]\n",
      "[[6 1]]\n",
      "[[5 0]]\n",
      "[[3 6]]\n",
      "[[6 4]]\n",
      "[[0 0]]\n",
      "[[1 4]]\n",
      "[[2 4]]\n",
      "[[2 6]]\n",
      "[[3 0]]\n",
      "[[0 5]]\n",
      "[[3 6]]\n",
      "[[1 6]]\n",
      "[[1 5]]\n",
      "[[2 6]]\n",
      "[[5 4]]\n",
      "[[6 5]]\n",
      "[[6 4]]\n",
      "[[0 4]]\n",
      "[[3 1]]\n",
      "[[1 2]]\n",
      "[[0 4]]\n",
      "[[3 5]]\n",
      "[[4 6]]\n",
      "[[1 5]]\n",
      "[[1 4]]\n",
      "[[5 0]]\n",
      "[[3 2]]\n",
      "[[6 0]]\n",
      "[[4 6]]\n",
      "[[2 4]]\n",
      "[[2 5]]\n",
      "[[3 1]]\n",
      "[[0 5]]\n",
      "[[3 6]]\n",
      "[[1 6]]\n",
      "[[1 5]]\n",
      "[[2 5]]\n",
      "[[2 6]]\n",
      "[[4 6]]\n",
      "[[5 4]]\n",
      "[[6 5]]\n",
      "[[6 4]]\n",
      "[[0 4]]\n",
      "[[3 1]]\n",
      "[[1 2]]\n",
      "[[0 3]]\n",
      "[[3 4]]\n",
      "[[4 5]]\n",
      "[[1 4]]\n",
      "[[1 3]]\n",
      "[[5 0]]\n",
      "[[5 1]]\n",
      "[[6 1]]\n",
      "[[3 4]]\n",
      "[[3 5]]\n",
      "[[4 1]]\n",
      "[[0 5]]\n",
      "[[3 6]]\n",
      "[[1 6]]\n",
      "[[1 5]]\n",
      "[[3 5]]\n",
      "[[3 6]]\n",
      "[[5 6]]\n",
      "[[5 3]]\n",
      "[[6 4]]\n",
      "[[6 3]]\n",
      "[[0 3]]\n",
      "[[3 0]]\n",
      "[[1 1]]\n",
      "[[1 3]]\n",
      "[[4 4]]\n",
      "[[5 5]]\n",
      "[[2 4]]\n",
      "[[2 3]]\n",
      "[[5 0]]\n",
      "[[5 1]]\n",
      "[[6 1]]\n",
      "[[4 4]]\n",
      "[[3 4]]\n",
      "[[3 6]]\n",
      "[[4 0]]\n",
      "[[0 5]]\n",
      "[[3 6]]\n",
      "[[1 6]]\n",
      "[[1 5]]\n",
      "[[3 4]]\n",
      "[[0 6]]\n",
      "[[3 5]]\n",
      "[[5 5]]\n",
      "[[5 3]]\n",
      "[[6 4]]\n",
      "[[6 3]]\n",
      "[[0 3]]\n",
      "[[3 0]]\n",
      "[[1 1]]\n",
      "[[0 3]]\n",
      "[[3 4]]\n",
      "[[4 5]]\n",
      "[[1 4]]\n",
      "[[1 3]]\n",
      "[[5 1]]\n",
      "[[5 2]]\n",
      "[[6 2]]\n",
      "[[4 3]]\n",
      "[[3 4]]\n",
      "[[3 6]]\n",
      "[[0 6]]\n",
      "[[1 6]]\n",
      "[[2 4]]\n",
      "[[2 5]]\n",
      "[[4 5]]\n",
      "[[5 2]]\n",
      "[[6 3]]\n",
      "[[6 2]]\n",
      "[[2 0]]\n",
      "[[0 1]]\n",
      "[[1 3]]\n",
      "[[4 4]]\n",
      "[[5 5]]\n",
      "[[2 4]]\n",
      "[[2 3]]\n",
      "[[5 1]]\n",
      "[[5 2]]\n",
      "[[6 2]]\n",
      "[[2 4]]\n",
      "[[2 6]]\n",
      "[[1 6]]\n",
      "[[2 6]]\n",
      "[[2 5]]\n",
      "[[2 6]]\n",
      "[[4 6]]\n",
      "[[5 2]]\n",
      "[[6 3]]\n",
      "[[6 2]]\n",
      "[[0 0]]\n",
      "[[0 3]]\n",
      "[[3 4]]\n",
      "[[4 5]]\n",
      "[[1 4]]\n",
      "[[1 3]]\n",
      "[[5 1]]\n",
      "[[5 2]]\n",
      "[[6 2]]\n",
      "[[1 4]]\n",
      "[[1 6]]\n",
      "[[2 6]]\n",
      "[[3 6]]\n",
      "[[0 1]]\n",
      "[[3 5]]\n",
      "[[3 6]]\n",
      "[[5 6]]\n",
      "[[5 3]]\n",
      "[[6 4]]\n",
      "[[6 3]]\n",
      "[[0 4]]\n",
      "[[3 5]]\n",
      "[[4 6]]\n",
      "[[1 5]]\n",
      "[[1 4]]\n",
      "[[5 0]]\n",
      "[[5 1]]\n",
      "[[6 1]]\n",
      "[[1 5]]\n",
      "[[2 6]]\n",
      "[[3 6]]\n",
      "[[0 1]]\n",
      "[[3 4]]\n",
      "[[0 6]]\n",
      "[[3 5]]\n",
      "[[5 5]]\n",
      "[[5 3]]\n",
      "[[6 4]]\n",
      "[[6 3]]\n",
      "[[0 0]]\n",
      "[[1 4]]\n",
      "[[4 5]]\n",
      "[[5 6]]\n",
      "[[2 5]]\n",
      "[[2 4]]\n",
      "[[5 1]]\n",
      "[[5 2]]\n",
      "[[6 2]]\n",
      "[[1 6]]\n",
      "[[1 6]]\n",
      "[[2 6]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(env\u001B[38;5;241m.\u001B[39magents)):\n\u001B[0;32m      6\u001B[0m     action \u001B[38;5;241m=\u001B[39m [i,env\u001B[38;5;241m.\u001B[39magents[i]\u001B[38;5;241m.\u001B[39mpick_action(observation, env\u001B[38;5;241m.\u001B[39mgrid_size)]\n\u001B[1;32m----> 7\u001B[0m     observation, reward, terminated, info \u001B[38;5;241m=\u001B[39m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m terminated:\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "Input \u001B[1;32mIn [3]\u001B[0m, in \u001B[0;36mfoodCollectorEnv.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m    118\u001B[0m observation \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_obs()\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrender_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhuman\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 121\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_render_frame\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m info \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124magent_points\u001B[39m\u001B[38;5;124m\"\u001B[39m: [agent\u001B[38;5;241m.\u001B[39mpoints \u001B[38;5;28;01mfor\u001B[39;00m agent \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39magents]}\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_step \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "Input \u001B[1;32mIn [3]\u001B[0m, in \u001B[0;36mfoodCollectorEnv._render_frame\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    184\u001B[0m     canvas\u001B[38;5;241m.\u001B[39mblit(good_food_image, (gfl[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m pix_square_size, (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgrid_size \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m gfl[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m*\u001B[39m pix_square_size))\n\u001B[0;32m    186\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m bfl \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbad_food_locs:\n\u001B[1;32m--> 187\u001B[0m     bad_food_image \u001B[38;5;241m=\u001B[39m \u001B[43mpygame\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mevil_plant.png\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mconvert_alpha()\n\u001B[0;32m    188\u001B[0m     bad_food_image \u001B[38;5;241m=\u001B[39m pygame\u001B[38;5;241m.\u001B[39mtransform\u001B[38;5;241m.\u001B[39mscale(bad_food_image, (pix_square_size, pix_square_size))\n\u001B[0;32m    189\u001B[0m     canvas\u001B[38;5;241m.\u001B[39mblit(bad_food_image, (bfl[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m pix_square_size, (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgrid_size \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m bfl[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m*\u001B[39m pix_square_size))\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "observation = env._get_obs()\n",
    "while True:\n",
    "    \n",
    "    for i in range(len(env.agents)):\n",
    "        \n",
    "        action = [i,env.agents[i].pick_action(observation, env.grid_size)]\n",
    "        observation, reward, terminated, info = env.step(action)\n",
    "\n",
    "    if terminated:\n",
    "        break\n",
    "pygame.quit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(info)\n",
    "np.argmax(info['agent_points'])\n",
    "print(f\"Agent {np.argmax(info['agent_points'])} wins the game with {max(info['agent_points'])} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env.agents[0].memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env.agents[0].memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tcod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### graph = tcod.path.CustomGraph((env.grid_size, env.grid_size))\n",
    "cost = env.grid.astype(np.int64)\n",
    "CARDINAL =[[0,1,0],[1,0,1],[0,1,0]]\n",
    "graph.add_edges(edge_map=CARDINAL, cost=cost)\n",
    "pf = tcod.path.Pathfinder(graph)\n",
    "pf.add_root((0, 0))\n",
    "pf.resolve()\n",
    "paths = [pf.path_to(x) for x in ((1,3), (4,5))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}