{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABD2\n",
    "\n",
    "Wij gaan tijdens deze opdracht een food-collector simulatie bouwen.\n",
    "In deze simulatie is het doel van de agents om zo veel mogelijk groen eten op te eten, terwijl ze rood eten vermijden.\n",
    "We gaan deze simulatie grid-based maken. \n",
    "\n",
    "We maken gebruik van de gymnasium API: https://gymnasium.farama.org/\n",
    "\n",
    "Ter visualisatie gebruiken we pygame.\n",
    "\n",
    "\n",
    "### Simulation properties:\n",
    "We beginnen in principe met een grid van 128x128, maar dit kan uitgebreid worden. \n",
    "We zullen de implementatie zoveel mogelijk scalable en aanpasbaar implementeren, door hyperparameters aan te maken voor alle belangrijke properties.\n",
    "\n",
    "- Number of agents\n",
    "- Grid size (default 128x128)\n",
    "- Good food to total square ratio\n",
    "- Good food spawning pattern (maybe)\n",
    "- Bad food to total square ratio\n",
    "- Bad food spawning pattern (maybe)\n",
    "- Episode duration\n",
    "\n",
    "### Agent properties:\n",
    "Actions: up, down, left, right, wait\n",
    "Perception: full information (knows coordinates of other agents, good food, and bad food)\n",
    "Agent rules: not yet specified\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pygame\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import random\n",
    "import time\n",
    "import tcod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class agent():\n",
    "    def __init__(self):\n",
    "        self.location = [None, None]\n",
    "        self.points = 0\n",
    "        self.vision_range = 4\n",
    "        self.memory = []\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([0, 0]),\n",
    "            1: np.array([1, 0]),\n",
    "            2: np.array([0, 1]),\n",
    "            3: np.array([-1, 0]),\n",
    "            4: np.array([0, -1])\n",
    "        }\n",
    "        self.path = []\n",
    "\n",
    "    def move(self, direction, grid_size):\n",
    "        new_location = self.location + direction\n",
    "        self.location = list(new_location)\n",
    "\n",
    "    def clip_vision(self, obs):\n",
    "\n",
    "        clipped_obs = {}\n",
    "\n",
    "        for k in obs.keys():\n",
    "\n",
    "            clipped_obs[k] = [x for x in obs[k]\n",
    "                      if abs(self.location[0] - x[0]) <= self.vision_range\n",
    "                      and abs(self.location[1] - x[1]) <= self.vision_range\n",
    "                     ]\n",
    "\n",
    "        return clipped_obs\n",
    "    \n",
    "    def get_best_move(self, obs, grid_size):\n",
    "        \n",
    "        cost = np.full((self.vision_range*2 + 1, self.vision_range*2 + 1),2)\n",
    "        \n",
    "        for k in obs.keys():\n",
    "            \n",
    "            new_coords = [[x-self.location[0] + self.vision_range,y-self.location[1]+ self.vision_range]  for x,y in obs[k]]\n",
    "            \n",
    "            if k == 'bad_food_locs':\n",
    "                for x in new_coords:\n",
    "                    cost[x[0]][x[1]] = 20\n",
    "                    #zou dit niet 0 moeten zijn? nu loopt ie over bad food als dat de enige viable route is, maar dat is niet de bedoeling toch?\n",
    "                    pass\n",
    "            if k == 'good_food_locs':\n",
    "                for x in new_coords:\n",
    "                    cost[x[0]][x[1]] = 1\n",
    "            if k == 'agent_locs':\n",
    "                for x in new_coords:\n",
    "                    cost[x[0]][x[1]] = 0\n",
    "            \n",
    "            # out of bounds squares get value 0\n",
    "            for x in np.argwhere(cost != None):\n",
    "                converted_coord = (np.array(x) - np.array([self.vision_range,self.vision_range]) + self.location)\n",
    "                if converted_coord[0] > grid_size -1 or converted_coord[0] < 0 or converted_coord[1] > grid_size -1 or converted_coord[1] < 0:\n",
    "                    cost[x[0]][x[1]] = 0\n",
    "                    \n",
    "                \n",
    "        good_food_converted_locs = list(zip(*np.where(cost == 1)))\n",
    "        # rotating the cost matrix 90 degrees somehow works\n",
    "        #cost = np.rot90(cost, k=1, axes=(0, 1))\n",
    "    \n",
    "        cost = cost.astype(np.int8) #changed type, now it works\n",
    "        graph = tcod.path.SimpleGraph(cost = cost, cardinal =1, diagonal = 0)\n",
    "        pf = tcod.path.Pathfinder(graph)\n",
    "        pf.add_root((self.vision_range, self.vision_range))\n",
    "        pf.resolve()\n",
    "        \n",
    "           \n",
    "        best_move = None\n",
    "        paths = [pf.path_to(cl)[1:].tolist() for cl in good_food_converted_locs if len(pf.path_to(cl)[1:].tolist()) != 0]\n",
    "\n",
    "        self.path = []\n",
    "        if len(paths) > 0:\n",
    "            shortest_path_index = np.argmin([len(x) for x in paths])\n",
    "            for x in paths[shortest_path_index]:\n",
    "                #undo the earlier conversion:\n",
    "                self.path.append(list(np.array(x) - np.array([-self.location[0] + self.vision_range,-self.location[1]+ self.vision_range])))\n",
    "            best_move = list(np.array(paths[shortest_path_index][0]) - np.array([self.vision_range, self.vision_range]))\n",
    "        \n",
    "        return best_move\n",
    "            \n",
    "\n",
    "    def pick_action(self,obs, grid_size):\n",
    "        \n",
    "        # clip the observation to the agents vision\n",
    "        obs = self.clip_vision(obs)\n",
    "                \n",
    "        best_move = self.get_best_move(obs, grid_size)\n",
    "\n",
    "        viable_actions = list(self._action_to_direction.keys())\n",
    "\n",
    "        other_agent_locations = [x for x in obs['agent_locs'] if x != self.location]\n",
    "\n",
    "        # Rule 1: agents can't move to a space occupied by another agent\n",
    "        viable_actions = [v for v in viable_actions if list(self.location +  self._action_to_direction[v]) not in other_agent_locations]\n",
    "        # Rule 2: agents can't move out of bounds\n",
    "        viable_actions = [v for v in viable_actions\n",
    "                          if list(self.location +  self._action_to_direction[v])[0] >= 0\n",
    "                          and list(self.location +  self._action_to_direction[v])[1] >= 0\n",
    "                          and list(self.location +  self._action_to_direction[v])[0] < grid_size\n",
    "                          and list(self.location +  self._action_to_direction[v])[1] < grid_size]\n",
    "        \n",
    "\n",
    "        #Rule 3: never step on bad food\n",
    "        viable_actions = [k for k,v in {v:list(self.location + self._action_to_direction[v]) for v in viable_actions}.items()\n",
    "                          if v not in obs['bad_food_locs']]\n",
    "        \n",
    "        #Rule 4: don't go back to zones where the agent has seen no good food\n",
    "        viable_actions_higher_prio = [k for k,v in {v:list(self.location + self._action_to_direction[v]) for v in viable_actions}.items()\n",
    "                          if v not in [x['agent_location'] for x in self.memory if len(x['agent_obs']['good_food_locs'])==0]]\n",
    "     \n",
    "        if best_move == None:\n",
    "            if len(viable_actions_higher_prio) > 0:\n",
    "                action = random.choice(viable_actions_higher_prio)\n",
    "            else:\n",
    "                action = random.choice(viable_actions)\n",
    "            \n",
    "        else:\n",
    "\n",
    "            action = [x[0] for x in list(self._action_to_direction.items()) if x[1][0] == best_move[0] and x[1][1] == best_move[1]][0]\n",
    "\n",
    "        self.memory.append({'agent_action':action, \"agent_obs\":obs, \"agent_location\":self.location})\n",
    "        return action\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class foodCollectorEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", None], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self, render_mode=None, grid_size=128, game_duration=200, agents=1, good_food_ratio=0.1,\n",
    "                 bad_food_ratio=0.1):\n",
    "        self.grid_size = grid_size\n",
    "        self.window_size = 720\n",
    "        self.game_duration = game_duration * agents\n",
    "        self.current_step = 0\n",
    "        self.agents = [agent() for _ in range(agents)]\n",
    "        self.good_food_ratio = good_food_ratio\n",
    "        self.bad_food_ratio = bad_food_ratio\n",
    "        self.good_food_points = 5\n",
    "        self.bad_food_points = -1\n",
    "        self.render_mode = render_mode\n",
    "        self.window = None\n",
    "        self.grid = np.ones((self.grid_size, self.grid_size))\n",
    "\n",
    "\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'agent_locs': spaces.Sequence(spaces.MultiDiscrete([self.grid_size - 1, self.grid_size - 1])),\n",
    "            'good_food_locs': spaces.Sequence(spaces.MultiDiscrete([self.grid_size - 1, self.grid_size - 1])),\n",
    "            'bad_food_locs': spaces.Sequence(spaces.MultiDiscrete([self.grid_size - 1, self.grid_size - 1])),\n",
    "        })\n",
    "\n",
    "        self.action_space = spaces.Sequence(spaces.Tuple((spaces.MultiDiscrete(len(self.agents)) ,spaces.MultiDiscrete(5) )))\n",
    "\n",
    "        self._action_to_direction = {\n",
    "            0: np.array([0, 0]),\n",
    "            1: np.array([1, 0]),\n",
    "            2: np.array([0, 1]),\n",
    "            3: np.array([-1, 0]),\n",
    "            4: np.array([0, -1])\n",
    "        }\n",
    "\n",
    "        self.good_food_locations = []\n",
    "        self.bad_food_locations = []\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return {\n",
    "            \"agent_locs\": [agent.location for agent in self.agents],\n",
    "            \"good_food_locs\": self.good_food_locs,\n",
    "            \"bad_food_locs\": self.bad_food_locs\n",
    "        }\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        self.agent_locs = []\n",
    "        self.good_food_locs = []\n",
    "        self.bad_food_locs = []\n",
    "\n",
    "\n",
    "        # place agents\n",
    "        while True:\n",
    "            if len(self.agent_locs) >= len(self.agents):\n",
    "                break\n",
    "            loc = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]\n",
    "            if loc not in self.agent_locs:\n",
    "                self.agent_locs.append(loc)\n",
    "\n",
    "\n",
    "        # place good food\n",
    "        while True:\n",
    "            if len(self.good_food_locs) >= round(self.good_food_ratio * self.grid_size * self.grid_size):\n",
    "                break\n",
    "            loc = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]\n",
    "            if loc not in self.agent_locs and loc not in self.good_food_locs and loc not in self.bad_food_locs:\n",
    "                self.good_food_locs.append(loc)\n",
    "\n",
    "        #place bad food\n",
    "        while True:\n",
    "            if len(self.bad_food_locs) >= round(self.bad_food_ratio * self.grid_size * self.grid_size):\n",
    "                break\n",
    "            loc = [random.randint(0, self.grid_size - 1), random.randint(0, self.grid_size - 1)]\n",
    "            if loc not in self.agent_locs and loc not in self.good_food_locs and loc not in self.bad_food_locs:\n",
    "                self.bad_food_locs.append(loc)\n",
    "\n",
    "        for i, agent in enumerate(self.agents):\n",
    "            agent.location = self.agent_locs[i]\n",
    "        \n",
    "        observation = self._get_obs()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "\n",
    "        info = {\"agent_points\": [agent.points for agent in self.agents]}\n",
    "\n",
    "\n",
    "\n",
    "        return observation, info\n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "\n",
    "        direction = self._action_to_direction[action[1]]\n",
    "        \n",
    "        self.agents[action[0]].move(direction, self.grid_size)\n",
    "\n",
    "        if self.agents[action[0]].location in self.good_food_locs:\n",
    "            self.good_food_locs.remove(self.agents[action[0]].location)\n",
    "            self.agents[action[0]].points += self.good_food_points\n",
    "\n",
    "        if self.agents[action[0]].location in self.bad_food_locs:\n",
    "            self.bad_food_locs.remove(self.agents[action[0]].location)\n",
    "            self.agents[action[0]].points += self.bad_food_points\n",
    "\n",
    "        terminated = self.current_step >= self.game_duration or (len(self._get_obs()['good_food_locs']) == 0 and self.current_step > 0)\n",
    "        reward = 0 # niet relevant voor nu\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_frame()\n",
    "        info = {\"agent_points\": [agent.points for agent in self.agents]}\n",
    "\n",
    "        self.current_step += 1\n",
    "\n",
    "        return observation, reward, terminated, info\n",
    "\n",
    "    def _is_empty(self, loc):\n",
    "\n",
    "        for agent in self.agents:\n",
    "            if sorted(agent.location) == sorted(loc):\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode == \"rgb_array\":\n",
    "            return self._render_frame()\n",
    "\n",
    "    def _render_frame(self):\n",
    "        pygame.font.init()\n",
    "        font = pygame.font.Font(None, 24)\n",
    "        scoreboard_width = 0.2\n",
    "\n",
    "        if self.window is None and self.render_mode == \"human\":\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.window = pygame.display.set_mode(\n",
    "                (self.window_size + self.window_size * scoreboard_width, self.window_size)\n",
    "            )\n",
    "\n",
    "        canvas = pygame.Surface((self.window_size + self.window_size * scoreboard_width, self.window_size))\n",
    "        canvas.fill((204, 255, 229))\n",
    "        pix_square_size = (\n",
    "                self.window_size / self.grid_size\n",
    "        )\n",
    "\n",
    "\n",
    "        for i, agent in enumerate(self.agents):\n",
    "            #draw agent picture\n",
    "            deer_image = pygame.image.load(\"deer.png\").convert_alpha()\n",
    "            deer_image = pygame.transform.scale(deer_image, (pix_square_size, pix_square_size))\n",
    "            canvas.blit(deer_image, (agent.location[0] * pix_square_size, (self.grid_size - 1 - agent.location[1]) * pix_square_size))\n",
    "\n",
    "            #try to draw vision_range, a bit awkward imo\n",
    "            fov = pygame.Surface((pix_square_size * (agent.vision_range*2+1), pix_square_size * (agent.vision_range*2+1)))\n",
    "            fov.set_alpha(128)\n",
    "            fov.fill((137,137,137))\n",
    "            canvas.blit(fov, ((agent.location[0] * pix_square_size)-pix_square_size*agent.vision_range, ((self.grid_size - 1 - agent.location[1]) * pix_square_size) - pix_square_size * agent.vision_range))\n",
    "\n",
    "            #draw the background for the scoreboard\n",
    "            scoreboard_bg = pygame.Surface((self.window_size*scoreboard_width,self.window_size+self.window_size*scoreboard_width))\n",
    "            scoreboard_bg.fill((255, 255, 255))\n",
    "            scoreboard_bg.set_alpha(255)\n",
    "            canvas.blit(scoreboard_bg, (self.window_size, 0))\n",
    "            score_text = font.render(f\"{i}\", True, \"white\")\n",
    "            canvas.blit(score_text, (agent.location[0] * pix_square_size, (self.grid_size - 1 - agent.location[1]) * pix_square_size))\n",
    "\n",
    "            #scoreboard text\n",
    "            score_text = font.render(f'Agent {i} | {agent.points}', True, \"black\")\n",
    "            canvas.blit(score_text, (self.window_size + 10 , 10 + (i*50)))\n",
    "\n",
    "            #path to good food\n",
    "            if len(agent.path) > 1:\n",
    "                for coord in agent.path[1:]:\n",
    "                    #draw the path\n",
    "                    path = pygame.Surface((pix_square_size, pix_square_size))\n",
    "                    path.set_alpha(128)\n",
    "                    path.fill((255, 0, 0))\n",
    "                    canvas.blit(path, (coord[0] * pix_square_size, (self.grid_size - 1 - coord[1]) * pix_square_size))\n",
    "\n",
    "\n",
    "        for gfl in self.good_food_locs:\n",
    "            good_food_image = pygame.image.load(\"plant.png\").convert_alpha()\n",
    "            good_food_image = pygame.transform.scale(good_food_image, (pix_square_size, pix_square_size))\n",
    "            canvas.blit(good_food_image, (gfl[0] * pix_square_size, (self.grid_size - 1 - gfl[1]) * pix_square_size))\n",
    "\n",
    "        for bfl in self.bad_food_locs:\n",
    "            bad_food_image = pygame.image.load(\"evil_plant.png\").convert_alpha()\n",
    "            bad_food_image = pygame.transform.scale(bad_food_image, (pix_square_size, pix_square_size))\n",
    "            canvas.blit(bad_food_image, (bfl[0] * pix_square_size, (self.grid_size - 1 - bfl[1]) * pix_square_size))\n",
    "\n",
    "        for x in range(self.grid_size + 1):\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                color=0,\n",
    "                start_pos=(0, pix_square_size * x),\n",
    "                end_pos=(self.window_size, pix_square_size * x),\n",
    "                width=1,\n",
    "            )\n",
    "            pygame.draw.line(\n",
    "                canvas,\n",
    "                color=0,\n",
    "                start_pos=(pix_square_size * x, 0),\n",
    "                end_pos=(pix_square_size * x, self.window_size),\n",
    "                width=1,\n",
    "            )\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "\n",
    "            self.window.blit(canvas, canvas.get_rect())\n",
    "            pygame.event.pump()\n",
    "            pygame.display.update()\n",
    "\n",
    "            #self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        else:\n",
    "            return np.transpose(\n",
    "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = foodCollectorEnv(render_mode=\"human\", grid_size=32, game_duration=5000, agents=1, good_food_ratio=0.15,\n",
    "                       bad_food_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "({'agent_locs': [[8, 31]],\n  'good_food_locs': [[5, 24],\n   [31, 6],\n   [24, 11],\n   [14, 4],\n   [7, 6],\n   [17, 19],\n   [3, 16],\n   [25, 28],\n   [12, 3],\n   [13, 11],\n   [11, 7],\n   [2, 8],\n   [13, 9],\n   [16, 28],\n   [6, 24],\n   [4, 24],\n   [15, 15],\n   [13, 29],\n   [6, 19],\n   [25, 4],\n   [16, 15],\n   [11, 10],\n   [17, 14],\n   [23, 20],\n   [18, 11],\n   [27, 2],\n   [9, 14],\n   [18, 19],\n   [12, 6],\n   [22, 6],\n   [27, 14],\n   [10, 7],\n   [0, 7],\n   [9, 29],\n   [21, 10],\n   [12, 19],\n   [29, 22],\n   [27, 9],\n   [22, 26],\n   [10, 19],\n   [5, 1],\n   [3, 2],\n   [21, 31],\n   [17, 4],\n   [5, 14],\n   [1, 6],\n   [30, 28],\n   [10, 30],\n   [31, 30],\n   [28, 27],\n   [6, 17],\n   [11, 12],\n   [4, 11],\n   [21, 27],\n   [16, 8],\n   [30, 6],\n   [1, 5],\n   [11, 17],\n   [7, 7],\n   [8, 3],\n   [25, 3],\n   [21, 26],\n   [22, 21],\n   [12, 21],\n   [21, 2],\n   [12, 2],\n   [2, 27],\n   [20, 7],\n   [3, 17],\n   [9, 7],\n   [22, 0],\n   [4, 25],\n   [0, 12],\n   [20, 26],\n   [16, 11],\n   [3, 3],\n   [8, 22],\n   [26, 6],\n   [26, 16],\n   [31, 1],\n   [29, 14],\n   [15, 26],\n   [2, 31],\n   [13, 16],\n   [2, 6],\n   [22, 5],\n   [31, 10],\n   [12, 28],\n   [28, 2],\n   [0, 25],\n   [6, 15],\n   [4, 15],\n   [29, 9],\n   [1, 13],\n   [25, 2],\n   [26, 25],\n   [5, 25],\n   [13, 13],\n   [13, 27],\n   [24, 28],\n   [26, 24],\n   [15, 19],\n   [23, 3],\n   [12, 10],\n   [18, 22],\n   [9, 20],\n   [4, 18],\n   [24, 31],\n   [20, 19],\n   [11, 16],\n   [14, 15],\n   [2, 3],\n   [4, 23],\n   [24, 4],\n   [14, 29],\n   [12, 16],\n   [31, 17],\n   [25, 18],\n   [25, 23],\n   [23, 26],\n   [8, 21],\n   [19, 21],\n   [23, 14],\n   [13, 15],\n   [19, 20],\n   [30, 24],\n   [21, 21],\n   [26, 1],\n   [12, 31],\n   [15, 0],\n   [5, 2],\n   [12, 11],\n   [0, 1],\n   [6, 16],\n   [11, 31],\n   [4, 22],\n   [26, 9],\n   [10, 27],\n   [13, 20],\n   [14, 13],\n   [3, 20],\n   [11, 6],\n   [20, 1],\n   [23, 24],\n   [5, 4],\n   [13, 2],\n   [25, 16],\n   [21, 24],\n   [23, 7],\n   [11, 5],\n   [19, 4],\n   [28, 3],\n   [29, 23],\n   [17, 22]],\n  'bad_food_locs': [[12, 26],\n   [24, 9],\n   [0, 13],\n   [3, 25],\n   [28, 29],\n   [3, 13],\n   [16, 5],\n   [27, 0],\n   [19, 18],\n   [10, 20],\n   [29, 26],\n   [17, 29],\n   [1, 20],\n   [14, 25],\n   [19, 29],\n   [18, 2],\n   [27, 4],\n   [2, 11],\n   [7, 30],\n   [3, 14],\n   [29, 10],\n   [18, 17],\n   [9, 25],\n   [31, 31],\n   [1, 21],\n   [1, 4],\n   [14, 21],\n   [8, 6],\n   [27, 8],\n   [31, 24],\n   [8, 27],\n   [13, 14],\n   [19, 7],\n   [24, 5],\n   [2, 14],\n   [12, 15],\n   [22, 10],\n   [28, 23],\n   [30, 10],\n   [30, 31],\n   [15, 18],\n   [23, 25],\n   [9, 16],\n   [2, 0],\n   [28, 6],\n   [14, 19],\n   [16, 14],\n   [7, 12],\n   [16, 31],\n   [17, 25],\n   [13, 30],\n   [23, 4],\n   [10, 13],\n   [10, 29],\n   [2, 17],\n   [6, 0],\n   [27, 19],\n   [21, 29],\n   [25, 29],\n   [19, 13],\n   [14, 26],\n   [4, 20],\n   [15, 13],\n   [24, 12],\n   [17, 12],\n   [8, 23],\n   [11, 13],\n   [15, 25],\n   [5, 9],\n   [13, 22],\n   [11, 1],\n   [23, 8],\n   [26, 14],\n   [24, 29],\n   [15, 6],\n   [15, 24],\n   [18, 9],\n   [28, 8],\n   [7, 1],\n   [30, 1],\n   [20, 23],\n   [21, 30],\n   [2, 23],\n   [31, 8],\n   [28, 16],\n   [21, 28],\n   [18, 15],\n   [31, 20],\n   [17, 9],\n   [20, 2],\n   [5, 26],\n   [1, 27],\n   [6, 13],\n   [1, 12],\n   [31, 11],\n   [26, 12],\n   [29, 27],\n   [29, 2],\n   [18, 26],\n   [16, 0],\n   [20, 10],\n   [6, 28],\n   [22, 8],\n   [15, 2],\n   [8, 17],\n   [4, 9],\n   [15, 21],\n   [29, 19],\n   [12, 25],\n   [11, 27],\n   [22, 19],\n   [18, 18],\n   [8, 11],\n   [5, 17],\n   [17, 2],\n   [26, 18],\n   [24, 14],\n   [2, 2],\n   [13, 12],\n   [2, 28],\n   [19, 8],\n   [15, 14],\n   [28, 25],\n   [2, 22],\n   [3, 9],\n   [28, 17],\n   [17, 16],\n   [20, 8],\n   [7, 5],\n   [20, 13],\n   [25, 12],\n   [26, 28],\n   [11, 26],\n   [22, 25],\n   [15, 12],\n   [26, 4],\n   [4, 14],\n   [25, 19],\n   [1, 16],\n   [19, 28],\n   [14, 2],\n   [29, 6],\n   [18, 14],\n   [13, 26],\n   [10, 24],\n   [0, 19],\n   [31, 27],\n   [20, 15],\n   [22, 3],\n   [19, 6],\n   [23, 15],\n   [29, 31],\n   [31, 13],\n   [1, 29],\n   [6, 2],\n   [14, 8],\n   [21, 5],\n   [0, 18],\n   [29, 13],\n   [0, 3],\n   [14, 22],\n   [0, 31],\n   [26, 10],\n   [10, 3],\n   [31, 0],\n   [4, 1],\n   [30, 5],\n   [18, 23],\n   [1, 0],\n   [30, 29],\n   [30, 12],\n   [16, 2],\n   [7, 22],\n   [11, 21],\n   [10, 15],\n   [27, 5],\n   [8, 7],\n   [4, 8],\n   [23, 18],\n   [2, 4],\n   [17, 3],\n   [22, 14],\n   [19, 27],\n   [15, 5],\n   [21, 13],\n   [14, 12],\n   [29, 4],\n   [24, 0],\n   [2, 12],\n   [21, 4],\n   [14, 30],\n   [25, 0],\n   [9, 22],\n   [10, 28],\n   [17, 15],\n   [14, 28],\n   [18, 21],\n   [27, 27],\n   [7, 17],\n   [29, 1],\n   [16, 13],\n   [14, 1],\n   [9, 27],\n   [1, 24],\n   [3, 18],\n   [1, 7],\n   [19, 26],\n   [2, 7],\n   [8, 25],\n   [3, 4],\n   [31, 12],\n   [7, 26],\n   [27, 31],\n   [20, 25],\n   [11, 2],\n   [14, 0],\n   [14, 5],\n   [18, 25],\n   [17, 30],\n   [20, 21],\n   [14, 3],\n   [13, 24],\n   [5, 19],\n   [1, 8],\n   [21, 11],\n   [8, 14],\n   [22, 15],\n   [15, 9],\n   [15, 29],\n   [20, 9],\n   [18, 5],\n   [29, 11],\n   [14, 10],\n   [27, 23],\n   [21, 16],\n   [28, 11],\n   [31, 23],\n   [4, 30],\n   [3, 1],\n   [21, 18],\n   [30, 11],\n   [10, 25],\n   [15, 31],\n   [19, 11],\n   [21, 25],\n   [11, 25],\n   [4, 16],\n   [16, 3],\n   [18, 0],\n   [6, 18],\n   [8, 19],\n   [1, 1],\n   [27, 10],\n   [26, 23],\n   [4, 3],\n   [8, 10],\n   [24, 15],\n   [5, 8],\n   [5, 29],\n   [1, 17],\n   [18, 30],\n   [6, 7],\n   [17, 17],\n   [11, 11],\n   [31, 26],\n   [0, 29],\n   [12, 13],\n   [20, 28],\n   [6, 10],\n   [8, 13],\n   [4, 5],\n   [8, 16],\n   [9, 11],\n   [28, 7],\n   [7, 23],\n   [19, 31],\n   [3, 28],\n   [8, 26],\n   [1, 28],\n   [30, 20],\n   [19, 0],\n   [19, 15],\n   [3, 6],\n   [9, 15],\n   [3, 26],\n   [27, 20],\n   [31, 14],\n   [30, 22],\n   [31, 7],\n   [28, 13],\n   [14, 18],\n   [10, 2],\n   [19, 3],\n   [24, 1],\n   [1, 22],\n   [6, 9],\n   [25, 8],\n   [3, 8],\n   [14, 6],\n   [28, 4],\n   [3, 0],\n   [0, 0],\n   [18, 4],\n   [16, 27],\n   [17, 26],\n   [1, 30],\n   [30, 15],\n   [24, 26],\n   [18, 12],\n   [21, 22],\n   [10, 22],\n   [21, 15],\n   [5, 27],\n   [15, 7],\n   [6, 26],\n   [0, 14],\n   [13, 28],\n   [30, 17],\n   [17, 23],\n   [3, 10],\n   [2, 29],\n   [8, 2],\n   [6, 30],\n   [30, 21],\n   [24, 27],\n   [16, 10],\n   [0, 23],\n   [27, 30],\n   [0, 8],\n   [25, 27],\n   [7, 24],\n   [23, 30],\n   [16, 30],\n   [17, 8],\n   [5, 3],\n   [20, 18],\n   [14, 31],\n   [2, 9],\n   [13, 3],\n   [7, 31],\n   [9, 18],\n   [27, 18],\n   [9, 2],\n   [10, 9],\n   [28, 21],\n   [27, 17],\n   [15, 4],\n   [8, 24],\n   [17, 10],\n   [6, 8],\n   [20, 30],\n   [22, 9],\n   [11, 3],\n   [22, 18],\n   [6, 12],\n   [18, 29],\n   [3, 7],\n   [25, 17],\n   [1, 2],\n   [1, 23],\n   [7, 9],\n   [25, 22],\n   [11, 8],\n   [6, 14],\n   [28, 1],\n   [6, 29],\n   [5, 22],\n   [23, 16],\n   [11, 24],\n   [5, 23],\n   [4, 31],\n   [0, 17],\n   [5, 30],\n   [12, 18],\n   [7, 13],\n   [29, 28],\n   [8, 1],\n   [5, 11],\n   [6, 6],\n   [18, 31],\n   [10, 0],\n   [25, 14],\n   [21, 14],\n   [31, 21],\n   [10, 12],\n   [24, 24],\n   [8, 4],\n   [27, 22],\n   [28, 28],\n   [0, 10],\n   [21, 17],\n   [10, 21],\n   [5, 18],\n   [28, 22],\n   [15, 8],\n   [22, 11],\n   [19, 24],\n   [23, 28],\n   [7, 25],\n   [16, 21],\n   [27, 6],\n   [9, 26],\n   [0, 9],\n   [4, 10],\n   [30, 26],\n   [20, 14],\n   [14, 27],\n   [11, 23],\n   [15, 10],\n   [26, 29],\n   [24, 13],\n   [10, 8],\n   [23, 27],\n   [24, 22],\n   [9, 31],\n   [12, 17],\n   [6, 11],\n   [6, 21],\n   [19, 14],\n   [8, 5],\n   [8, 29],\n   [6, 4],\n   [11, 20],\n   [29, 24],\n   [28, 24],\n   [2, 13],\n   [20, 31],\n   [27, 21],\n   [3, 15],\n   [23, 29],\n   [8, 15],\n   [10, 18],\n   [31, 3],\n   [21, 12],\n   [13, 1],\n   [26, 17],\n   [17, 21],\n   [10, 23],\n   [3, 24],\n   [23, 22],\n   [30, 19],\n   [16, 25],\n   [17, 1],\n   [5, 20],\n   [10, 4],\n   [15, 3],\n   [21, 23],\n   [24, 2],\n   [4, 26],\n   [5, 21],\n   [17, 24],\n   [28, 5],\n   [22, 13],\n   [9, 23],\n   [13, 25],\n   [30, 7],\n   [8, 28],\n   [23, 0],\n   [26, 0],\n   [6, 27],\n   [25, 13],\n   [18, 8],\n   [27, 13],\n   [5, 13],\n   [22, 30],\n   [10, 11],\n   [13, 5],\n   [30, 27],\n   [4, 4],\n   [19, 12],\n   [16, 4],\n   [12, 20],\n   [20, 6],\n   [24, 20],\n   [27, 24],\n   [8, 30],\n   [9, 3],\n   [23, 13],\n   [25, 24],\n   [7, 19],\n   [0, 6],\n   [6, 20],\n   [3, 5],\n   [9, 24],\n   [16, 7],\n   [20, 4],\n   [18, 3],\n   [22, 16],\n   [0, 22],\n   [7, 0],\n   [31, 2],\n   [19, 2],\n   [2, 15],\n   [24, 17],\n   [19, 19],\n   [21, 1],\n   [28, 10],\n   [0, 20],\n   [23, 17],\n   [6, 3],\n   [9, 30],\n   [13, 4],\n   [26, 13],\n   [4, 27],\n   [11, 9],\n   [17, 28],\n   [3, 12],\n   [10, 26],\n   [23, 23],\n   [19, 30],\n   [13, 21],\n   [20, 29]]},\n {'agent_points': [0]})"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[51], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(env\u001B[38;5;241m.\u001B[39magents)):\n\u001B[0;32m      6\u001B[0m     action \u001B[38;5;241m=\u001B[39m [i,env\u001B[38;5;241m.\u001B[39magents[i]\u001B[38;5;241m.\u001B[39mpick_action(observation, env\u001B[38;5;241m.\u001B[39mgrid_size)]\n\u001B[1;32m----> 7\u001B[0m     observation, reward, terminated, info \u001B[38;5;241m=\u001B[39m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m terminated:\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[48], line 114\u001B[0m, in \u001B[0;36mfoodCollectorEnv.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m    111\u001B[0m observation \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_obs()\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrender_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhuman\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_render_frame\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    115\u001B[0m info \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124magent_points\u001B[39m\u001B[38;5;124m\"\u001B[39m: [agent\u001B[38;5;241m.\u001B[39mpoints \u001B[38;5;28;01mfor\u001B[39;00m agent \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39magents]}\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_step \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "Cell \u001B[1;32mIn[48], line 192\u001B[0m, in \u001B[0;36mfoodCollectorEnv._render_frame\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    189\u001B[0m     canvas\u001B[38;5;241m.\u001B[39mblit(good_food_image, (gfl[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m pix_square_size, (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgrid_size \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m gfl[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m*\u001B[39m pix_square_size))\n\u001B[0;32m    191\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m bfl \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbad_food_locs:\n\u001B[1;32m--> 192\u001B[0m     bad_food_image \u001B[38;5;241m=\u001B[39m \u001B[43mpygame\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mevil_plant.png\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mconvert_alpha()\n\u001B[0;32m    193\u001B[0m     bad_food_image \u001B[38;5;241m=\u001B[39m pygame\u001B[38;5;241m.\u001B[39mtransform\u001B[38;5;241m.\u001B[39mscale(bad_food_image, (pix_square_size, pix_square_size))\n\u001B[0;32m    194\u001B[0m     canvas\u001B[38;5;241m.\u001B[39mblit(bad_food_image, (bfl[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m pix_square_size, (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgrid_size \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m bfl[\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;241m*\u001B[39m pix_square_size))\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "observation = env._get_obs()\n",
    "while True:\n",
    "    \n",
    "    for i in range(len(env.agents)):\n",
    "        \n",
    "        action = [i,env.agents[i].pick_action(observation, env.grid_size)]\n",
    "        observation, reward, terminated, info = env.step(action)\n",
    "\n",
    "    if terminated:\n",
    "        break\n",
    "pygame.quit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(info)\n",
    "np.argmax(info['agent_points'])\n",
    "print(f\"Agent {np.argmax(info['agent_points'])} wins the game with {max(info['agent_points'])} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1,3] in [[1,3],[3,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
